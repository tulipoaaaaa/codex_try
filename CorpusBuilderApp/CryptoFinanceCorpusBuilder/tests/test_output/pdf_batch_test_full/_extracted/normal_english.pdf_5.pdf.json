{
  "title": "Attention is All you Need",
  "author": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin",
  "subject": "Neural Information Processing Systems http://nips.cc/",
  "creator": "",
  "producer": "PyPDF2",
  "creation_date": "",
  "modification_date": "D:20180212212210-08'00'",
  "domain": "unknown",
  "quality_metrics": {
    "language_confidence": {
      "language": "en",
      "language_confidence": 0.9999981959285954,
      "mixed_language_flag": true,
      "mixed_languages": [
        "en"
      ],
      "reasons": [
        "Mixed languages detected: [('en', 0.9095477386934674)]"
      ],
      "severity": "warning"
    },
    "corruption": {
      "corruption_flag": false,
      "corruption_score": 40,
      "corruption_score_normalized": 40,
      "corruption_reasons": [
        "Found corruption markers: ",
        "High ratio of replacement characters (possible encoding issue)"
      ],
      "severity": "warning"
    },
    "machine_translation": {
      "machine_translated_flag": false,
      "machine_translation_score": 0,
      "machine_translation_reasons": [
        "Code pattern detected"
      ],
      "machine_translation_severity": "ok",
      "machine_translation_confidence": 0.0
    },
    "academic_analysis": {
      "is_academic_paper": true,
      "confidence": 0.6,
      "score": 9,
      "indicators_found": [
        "abstract",
        "introduction",
        "methods",
        "results",
        "conclusion",
        "references",
        "appendix",
        "citations"
      ],
      "citation_count": 88,
      "recommended_thresholds": {
        "min_tokens": 200,
        "low_quality_tokens": 1000,
        "reference_density_max": 0.15,
        "citation_density_max": 0.1,
        "formula_density_max": 0.2,
        "table_density_max": 0.15,
        "min_sections": 3,
        "bibliography_required": true
      }
    },
    "content_validation": {
      "passes_academic_standards": true,
      "issues": [],
      "adjustments_made": [
        "Reference density within academic norms"
      ]
    },
    "symbol_richness": {
      "total_symbols": 195,
      "unique_symbols": 43,
      "financial_symbols": 0
    },
    "min_tokens": 200,
    "low_quality_tokens": 1000,
    "reference_density_max": 0.15,
    "citation_density_max": 0.1,
    "formula_density_max": 0.2,
    "table_density_max": 0.15,
    "min_sections": 3,
    "bibliography_required": true,
    "extraction_quality": {
      "tables_detected": true,
      "formulas_detected": true,
      "charts_detected": true,
      "symbols_detected": true,
      "token_count": 5020,
      "quality_flag": "ok",
      "is_academic_paper": true,
      "academic_confidence": 0.6
    }
  },
  "is_scientific_paper": true,
  "content_hash": "60e6c164d8c36f58950dd51cd6ee5116",
  "file_size": 569417,
  "extraction_date": "2025-05-26T17:56:33.754112+00:00",
  "enhancement_results": {
    "formulas": {
      "formulas": [
        {
          "formula": "1/4",
          "type": "fractions",
          "position": {
            "start": 23134,
            "end": 23137
          },
          "context": "previously published single models, at less than 1/4 the training cost of the\nprevious state-of-the-ar",
          "confidence": 0.3,
          "metadata": {
            "length": 3,
            "has_greek_letters": false,
            "has_superscript": false,
            "has_subscript": false,
            "has_fractions": true,
            "has_integrals": false,
            "has_summations": false,
            "complexity_score": 0.05,
            "source": "fractions"
          }
        },
        {
          "formula": "Attention Is All You Need\nAshish Vaswani” Noam Shazeee” NIKI Parmar” Jakob Usekoret™\nGoogle Bes Goosle Brain Google Research Google Research\navecuansGgeople.com noentgeogle-com aikiplgoogle-con ueztgoagle.com\nlon Jones” Aidan N. Gomer’! akass Kalser™\nGoogle Research University of Texoma Google Brain\nLiienOgoogle con aidantece.torente,edi  Tukaazkaleertgoogle.com\nMa Potosukhin™\nAbstract\n‘The dominant sequence transduction models are based on complex rcurent or\nconvolutional neural nerworks tha include an encoder and a decoder. The best\npevfonming models alo connect the encoder and decoder though an ateation\n{echanism We proposes new simple network areitecture, the Transformer\nbased solely on atention mechanishs. dispensing with recuence and convolution:\nenliely. Experiments on to machine vansation tsks show these model 19\nbe superiors quality while being moe parallelzable and regu sgnican\nTess tne t tala. Our model achieves 284 BLEU onthe WMT 2014 English\n‘o-German wansation tsk, improving over the existing best esl incling\n‘tebe, by over? BLEU. On the WMT 2014 English-French nsltion ask,\nfourmode establishes ew single-modl sate-ofde-a BLEU sete of 10 afer\n{tuning for 3-5 days on eight GPUs, xsl fraction ofthe taining costs ofthe\ntest model from the Uteratu\n1 Introduction\nRecurrent neural networks, long short-term memory {12} and gated ecutent [7] acura networks\nin particular, have been fray established ss sate ofthe at approaches in sequence modeling and\n‘wansdaction problems such as language modeling and machine wanslton [39,2 5). Namerous\nefforts have tne conned to push he boundaries of recumen language model and cncode-decaer\nSaehiecures (31.21.13\n1 aoa nis Geni. pope pang BN Wh leon ad\n‘fitted ans than aan a ay evgnng ta d",
          "type": "ocr_image",
          "page": 1,
          "confidence": 0.5,
          "source": "ocr_image",
          "metadata": {
            "length": 1756,
            "has_greek_letters": false,
            "has_superscript": false,
            "has_subscript": false,
            "has_fractions": true,
            "has_integrals": false,
            "has_summations": false,
            "complexity_score": 1.0,
            "source": "ocr_image"
          }
        },
        {
          "formula": "Recurrent modes typically factor computation along the symbol positions ofthe input nd outa\nSequences. Aligning the positions to steps in computation tine, they generate a sequence of hidden\n‘ues hy. function ofthe previous hidden staf ad the ip for poiton This inbeently\n‘cnet nature pecodes palliation win tuning examplen which becomes cial st longer\nSequence lengths as memory consis int batching across examples. Revest Work has achieved\nSignificant improvements in computational ficiency dough factoizaton tik [1] and condionl\n‘computation [2], while also amproving model performance in case ofthe ltt. The fundamental\n‘onsaitof sequential computation, however remais.\nAsteaton mechanisms have become a intepa pat of compelling Sequence modeling and ransduc\n‘ion model in various tsk, allowing modeling of dependencies without regard their distance ia\nthe inp or opr sequences (2.16 hall uta ew cae [22] however, sch tenon mechanisms\n‘se ed in conjunction with a ecuent network\nIn this work we propose the Tansforme, a model architecture eschewing recurrence and instead\nselyng entsely cn an ateaion mechansi to dew global dependences between inp and ouput\n‘The Transformer allows for sigecanly more pualelization and can each ew sata he ai\n‘ealtion uality afer being trained for lite steve outs om eight POO GPUs,\n2 Background\n‘The gol of educing sequential computation also forms the foundation ofthe Extended Neural GPU\n(20) ByteNet [15] and ConvS2S [sal of which use coavlutional neural networks as basic ulding\n‘lock computing hidden representations in parle! fr al input and output postions. Tn these models\n‘he number of operations requed to relate sighs roto abitary inp oF ouput sions grONS\ninthe dane between positions, lineal for ConvS2S and logurithncly for ByteNee. Ths takes\n{tmoce dificult learh dependencies between distant postions [11] Inthe transformer tis\nseduce toa constant numberof operations albeit tthe cost of reduced effective resolution doe\n{o averaging atenion weighted positions an effet we counteract wath Muli-Head Attention 35\n‘deseribed in section 32.\nSeleatenton, sometimes called in-atention i an atenton mechanism relating diferent posons\n‘fa single sequence in over wo compute a epresentauon of the sequence. Sel tention hasbeen\n‘sed successfully in aretyof asks including eadig comprehension, abstsctive summarization,\n‘extalenaleat and Tearing tsk-independont sentence fepeesttations (4,22, 23,19)\nEnd-to-end memory networks are based ona recutentstention mechanistn instead of sequence\naligned ecutence and ave been shown wo perform well on simple-anguage question answer abd\ninnguage modeling tasks [3]\n‘othe best of our knowledge, however, the Transformer isthe fist wansdaction model relying\nctiely on el-atention to compute epreseations of inp and ouput without using sequence\nSligned RNNS or convolution Inthe following sections, we wll describe the Tassormet. motte\nSel-ateation and discus is advantages over models such as [14 15] ad [8\n3) Model Architecture\n‘Most competitive neural sequence tansdction models have a encde-decoder structure [5,229\nHere, the encoder maps an input sequence of symbol representations (2...) toa sequence\nof continuous representations 2 = (.--,%,). Given 2 the decoder the generates ah oui\nSequence {y-- im) of symbols one element at atime, Ateac sep the model s autoregressive\n[bY consuming he previously generated symbols as addiinal input When generating the next\n‘The Transformer Follows this overall architecture using stacked self. attention and pointwise, fully\nacted layers or both the encoder and decoder, shown in the lft and sight halves of Figue 1,\n‘spectively.\n|JM_ Encoder and Decoder Stacks\nEncoder: ‘The encader is composed ofa stack of N’ = 6 ientical layers, Each layer has two\nsublayers, The fst ia mulchead sel-atention mechanism. and the second is sinple, positon.\n2",
          "type": "ocr_image",
          "page": 2,
          "confidence": 0.5,
          "source": "ocr_image",
          "metadata": {
            "length": 3871,
            "has_greek_letters": false,
            "has_superscript": false,
            "has_subscript": true,
            "has_fractions": false,
            "has_integrals": false,
            "has_summations": false,
            "complexity_score": 1.0,
            "source": "ocr_image"
          }
        },
        {
          "formula": "eal\n(Ce ss.\n“ Ca) =]\nErevan QP OE\n==) eas\n:",
          "type": "ocr_image",
          "page": 3,
          "confidence": 0.5,
          "source": "ocr_image",
          "metadata": {
            "length": 43,
            "has_greek_letters": false,
            "has_superscript": false,
            "has_subscript": false,
            "has_fractions": false,
            "has_integrals": false,
            "has_summations": false,
            "complexity_score": 0.15000000000000002,
            "source": "ocr_image"
          }
        },
        {
          "formula": "Séalot Do Pads Ateton Muli Head Aeon\n=)\na\nea a a\nCam SEDED\nFut 2: (ef) Sealed Do Product Aton, (igh) Mule Aneton consis of several\n‘von yes ean in oral\nery witha hy, vie cch by Vand apply soa action obtain te wah on the\nwhe\nInprcice, we comput te ation Fintona st of use simultansony pack ose\nIsmace . The keyed alter esa packed wgeler no mater aad V Weconpeas\ntention(@. KV) = ok\nAretion( 9.47) = fina 28 o\n\n‘The two mos conunnly wed tention factions adiveatentin (2 and da prod (ok\nleave) aenton, Dopod tenon ena our gor xc for sealing aor\nSr aLr Adve suennon compte te compat ncn singe foward twa th\nSs sligl hidden ayer Whe the gwo are sma inher eompleriy, dx got anton is\n‘mud ater an ane spacetici n pace, since ean be plement xing gh opis\n\"Wile fr smal lus of te wo mechani pero sina. ive ate ouperfoms\n{oe prodictateon wtousaing for rer vale of [3], Wesuapct tha for ge aes of\ndt he dn grote row lage a gna poring ihe sfx funciona pone wher hat\n‘Siemely all gradient coun heeft we sae the rods ot\n2122 Multead Attention\nInsta of peroming single teton faci with d-dmensiona Lys ves anders,\nte found i neta olineaty poet the quein eye and vals her wi dileen eaed\nThar projections od and denon rerpctely. On cach of exe projected veins of\n(Tien tes and ves then arflom he steno unto Ia all yelling d-mexconal\nShip wala These ae concatte and once gun oct tevin Salva\n‘ipetd in Pue 2\n‘Muti steton allows the mode! tony attend to infomation om diferent sesettion\n‘Stopes ite pono, Wit shops aero head, verging inh hk\n\n“isa wy i dics tls, ee ie compo of an a ned aon\nssi han Oana Pen i roc = Sy gi ha ae dr\n\n4",
          "type": "ocr_image",
          "page": 4,
          "confidence": 0.5,
          "source": "ocr_image",
          "metadata": {
            "length": 1610,
            "has_greek_letters": false,
            "has_superscript": false,
            "has_subscript": false,
            "has_fractions": false,
            "has_integrals": false,
            "has_summations": false,
            "complexity_score": 0.5,
            "source": "ocr_image"
          }
        },
        {
          "formula": "Mulettend(Q. K,V) = Concat( bead, )WV°\nwhore heads = Attention(QW®, KWH, VWY)\n\nWhere the projections are paneer maces 7 € RK Beans YY @ Rau\nand 170 € Ble\nIn this work we employ f= $ parallel atenton layers, heads. For each ofthese we use\n4, == degajh = 64 Dus to the reduced dimension ofeach head, the total computational cos\n{s silat tht ingle-ead tation with fll dimensional\n323 Applications of Attention in our Model\n‘The Transformer uses mul-head tention in thee different ways:\n\n‘+ In “encoderdecoder attention” layers, the queries come from the previous decode ayer\nsnd the mernoy keys and values come from the ouput ofthe encode. This allows every\npositon inthe decoder to atend ove al postions ia the input sequence. This mimes the\n\"ypical encode-decode attention mechanisms in sequence-toseguence models such as\nBL28)\n\n‘+ The encoder contains selF-atenion layers. In se atenton layer alo the Kes, values\nand queries come from the sane place inthis case, te outp ofthe previous layer inthe\n‘encoder. Each poston nthe encoder can attend tal positions inthe previous lye of the\nneeda\n\n«+ Simulay,ste-atention layers in the decoder allow each poston nthe decoder to stend to\nall positions inthe decoder upto and including that postion, We need io prevent leftward\n{information flowin the decoder to preserve the auo-eaessive peopety. We inplement his\nInside of sealed dot product attention by masking out Sting to >) al vals in he ipl\nofthe Sofa which conespond to llegal connections. See Figure 2\n\n133 Positon-wise Feed-Forward Networks\nln addition to ateaion sub-ayers, each ofthe layers in our encoder and decode contains fly\nconnected fod-orwatd network, whichis applied o each poston Separately and dentally. Ths\n‘onsets of wo linea rasformations with ReL.U activation in betwen,\n\nFFN(z) = man(0.2105 +05) +2 2\n‘While the liner transformations at the ste cos diferent postions they use different parameters\nfiom layer to layer. Another way of desing this i a tWo convoltions With kemel size 1\n‘The dimensionality of input atid Outpt is dy = 512, and the innelayer has dimensionality\nayy = 208,\n34 Embeddings and Softmas.\nSimilarly to eter sequence uansduction model, we use Ieamed embeddings 1 conver the inp\n‘okens afd ouput tokens tweets of dimension dy- We also use the usual eared ica wast\n‘maton and softmax function wo convert the decoder ouput to pedictednext-oken probable. 1a\n‘ou model, we share the sae Weight mats between the two embedding layers andthe presoftmak\nTear unsformaton,snulro [24]-In dhe embedding ayers, we mil those Weighs DY da\nAS- Posilonal Encoding\nSince ou model contains no reeureace and no convolution in eder fer he mode! to make use of the\n‘onder of the sequence, we must inj some information about the relative abou postion of he\n{okens ia the sequence. To this end, we add \"positional encodings” tothe input emedngs at the\n\ns",
          "type": "ocr_image",
          "page": 5,
          "confidence": 0.5,
          "source": "ocr_image",
          "metadata": {
            "length": 2871,
            "has_greek_letters": false,
            "has_superscript": false,
            "has_subscript": false,
            "has_fractions": false,
            "has_integrals": false,
            "has_summations": false,
            "complexity_score": 1.0,
            "source": "ocr_image"
          }
        },
        {
          "formula": "‘be L: Maxinum pt legis, prayer complexity and minimum numberof sequential operations\nFordifernt ayer types. ni the sequence length isthe representation dinension is the keel\nsine of conolutios andr the size of the neighborhood in rested selF-ateaon.\n“Toe hpe Complex per Layer Seqeeatal Maximum Pah Length\nOperations\n“SeieAteaion SSCS)\nRecurrent Oin- O(n) O(n)\nConvutonsl Oe na) oun) Ottoneind)\nSelb-Atenton esticed) Orn) ou) Olnr)\n‘toms ofthe encoder and decoder stack. The positional encodings hae the sme dimension das\n‘the embeddings, s thatthe two canbe sumed. There are ny choices of positional encodings\nTeumed nd fixed (8\nIn this wosk, we use sine and cosine functions of diferent frequencies:\nPE on) = sin\\p0s/ 100007\")\nPE gon 204) = €08(008/ 10000)\n‘whore pos isthe postion an is the dimension. That is, cach dimension ofthe positional encoding\noesponds oa sinusoid. The wavelengths form a geometric progression rom 2 10 10000 -27- We\n‘hose tis function because we hypthesied st would allow the model easly ea to atend by\nfelaive positions, since for any fed offiet PE. can be epescied a nea Tnetion of\nPE or\nWe als experimented with using lamed positional embeddings [8] insta and found thatthe 0\nversions produced newly idenical sults (ee Table 3 sow (E). We chose the sinusoidal version\n‘ocaus it may allow dhe model to extaplate to sequence lengths longer than the ones encountered\nsing unig\n4 Why Self-Attention\nln this section we compate various aspects of selattention layers othe recurteat and coavol\n‘oul layers commonly used Tor mapping one variable-length sequence of symbol presentations\n(host) to anaes sequence of equa length (2..u.25). with =, ©. such as a hidden\nlayer in typical sequence ansdaction encoder oe deoder, Moiaing ou use of slf-atetion we\nconsider te desideata,\n(One is the oa computational complexity per ayer. Anoter isthe amount of computation that can\n‘be parlelized s measured by the minimum number of sequential operations que,\n‘The thi isthe path lngth between loag-tange dependencies inthe network. Learins long-cange\ndependencies sky challenge ia many sequence uansduction aks. One key factor aflecting the\nbly to lear such dependencies i the length ofthe pts forward and backwatd signal have 10\n‘eaves in the network The shver these pas betwen any combination of postions in the ip\nan utp sequences the easier itso leat long-range dependencies [1], Hence we so compare\n‘he matimun path length between ay 1 ipl and output postions ia networks composed a he\nslrerent layer pes.\nAs notedin Table | aelfttenton layer connects all positions with constant number of ssquentilly\n‘executed operations, whereas recent layer segues O(n) sequeaual operations. In teams OF\n‘computational complexity. selF-atention layers ae faster tha ecurent ayers when the sequence\nTength ni smaller than the epresentaton dimensionality. which is moet often the cise with\nSenlonce repeseaations used by state-of-the-art models in machine wansations such as weed pcce\n[31] and byte par (25] representations. To improve computational performance foe asks involving\n‘ey long sequences slf-aenton could be ected vo considering oly osighborbood of sizer it\n6",
          "type": "ocr_image",
          "page": 6,
          "confidence": 0.5,
          "source": "ocr_image",
          "metadata": {
            "length": 3176,
            "has_greek_letters": true,
            "has_superscript": false,
            "has_subscript": false,
            "has_fractions": true,
            "has_integrals": false,
            "has_summations": false,
            "complexity_score": 1.0,
            "source": "ocr_image"
          }
        },
        {
          "formula": "the input sequence entered around the respective up positon, This would incest he maximum,\npath length Yo O(n). We plan to ivesigate this approach further in ute Week\nAsngle convolutional layer with kernel width & <n does not connec al pis of input and outa\npostions. Doing so requis astack of O(1/)comvaluonal layers inthe case of contiguous Keel,\n{¢ Ollog() inthe case of dilated convolution [5] ineeasing the length ofthe longest pals\n‘between any two positions in the network. Convolutional layers ae generally more expensive than\nsccurreat layers, by a factor of. Separable convolution [6]. however. decrease the comply\nConsiderably, © O(E nu +). Even with k= n, however, the complexity ofa separable\n“onvotion is equal othe combination of x seleatenion layer anda pointwise fsi-forwatd Lye,\n{he approach we take in our model\nAs side ene self tention could yield moeitrpetable models. We inspect tention dstabutions\nfiom our models and present and discuss examples in the appendix. Not only do individual rtention\n‘ead leary lar o perform diferent asks. many sppea to exhibit behavior veld to he sytactc\nsin semantic stucture ofthe sentences.\n5 Training\n‘This section describes the waining epime for our model\n54 Training Data and Batching\nWe tained oa the standard WMT 2014 English-Geeman dataset consisting of abou 4.5 milion\nsentence pais. Sentences were encoded using byt-par encoding [3], which isa shared source\n{aigtvocaulay of atout 37000 tokens. For English-French, we used the sigan lager WAIT\n2014 English-French dataset consising of 36M sentences and spit wokons ito a 32000 wond-pece\n‘ocablay [31 Sentence pis were batched together by approximate seguonce length, Each waning\nbatch contained ast of sentence puts conning approximately 25000 source tokens and 25000\ntaygt tokens.\n52. Hardware and Schedule\nWe trained our modes on one machine with ® NVIDIA P100 GPUs. For our base modes sing\nte yperparametesdesribed throughout the paper, each traning tp took about 0 seconds. We\ntwine the tase mls for tl of 10,000 step or 12 hours. For ou big models (described oa the\nbottom lie of ble 3), stp tne was 10 seconds, The big models were and for 300,000 steps\nGS days,\n53. Optimizer\nWe used the Adam optimize [17] with 2; = 0.9. 3, = 0.98 and « = 10-9, We vriod the leaning\nsate over the couse a waning, according othe fara\n‘Tis comesponds oincteasing the learning cate linearly forthe fst warmup. steps taining step,\naint doceatng i thereafter proportionally the iver square rot ofthe sep suber We ured\nSA Regularization\nWe employ tee types of regularization ding waning:\nResidual Dropout _ We apply dropout [27] othe ouput ofeach sub-ayer, before itis added othe\nsul-layer input and normalized. In addon, we apply dropout othe sums ofthe embedlings and he\npositional encodings in both he encoder and decoder stacks Fr the base medel, We use 2a Of\nPoop Ol\n\n1",
          "type": "ocr_image",
          "page": 7,
          "confidence": 0.5,
          "source": "ocr_image",
          "metadata": {
            "length": 2873,
            "has_greek_letters": false,
            "has_superscript": false,
            "has_subscript": true,
            "has_fractions": true,
            "has_integrals": false,
            "has_summations": false,
            "complexity_score": 1.0,
            "source": "ocr_image"
          }
        },
        {
          "formula": "‘Table 2: The Transformer achieves beter BLEU sores than pevius state-of the-art models the\nEnglish-o-Gennan and English-French newstest20d test at fraction of the uals cost.\nvoit BLEU “Training Cost FLOPS)\nol ENDE ENR EN-DE ENFR\nSBN TESTS\nDDeep-Att + PosUak (32) 302 10-108\nGNMT-+RL (SI) 246 3992 -28.10 L410\"\nConvs25 (81 25.16 4046 96-10% 15-108\"\n\nMar [26) 26034036 20-10 13:10\"\n~Decp-Att+PosUink Ensemble [2] O80\nGNMT-+RL Ensemble [31] 2630 416 18-10 L110\nConvs28 Ensen] dere 4439771013. 10\n\n“Tiansfomse (base model) 23a S510\n\n‘Transformer bi) 2a a0 23-10%\nLabel Smoothing During waning, we employed label smoothing of value «, = 0.1 (30). This\n‘nuts perplexity. as the model Teams to be more unsure, bu improves accuracy abd BLEU sco\n6 Results\n64 Machine Translation\n(On he WMT 2014 English German translation tsk, the big tansformer model (Tansformer Cig)\n{n Table 2 ouipesTorms the best eevieuly reported models icluing ensembles) BY moee than 20,\nBLEU, extablishing a new state-of-the-art BLEU cove of 28.4. The configuration of ths todel is\nTse inthe hotonline of Table 3. Training ook 3.5 days on 8 P1O0 GPUs. Even our hase model\nsurpasses al previously published models and ensembles aa ation ofthe waning cost of at) of\n‘he competitive model\n(On the WMT 2014 Englih-to French transition isk, ou big model achieves a BLEU score of 41.0,\n‘outperforming al ofthe previously published single modes a less han 1/ the waiing east of the\nfretous state-of the-at model. The Transom (big) model wained for Eaglish-o-French used\nropout ate Pay ~ listed oF 0\nFar the base models, we used a single model obtained by averaging the last S checkpoints, which\nwore writen at 10-minute intervals. Forte big models, we averaged the lst 20 checkpoints. We\n{od beam setch with a beam size of 1 and length penalty a= 06 [SI]. These hyperparametes\n‘were chosen ater experimentation onthe devlopmout se. West the maximus oupa length ding\nInference to input length + 5, but enninat eatly when possible [31\n“Table 2 summarizes our results and compares our uatsation quality and taining costs her model\nrchictures fromthe Hterature. We estinate the number of flatng point operations wed to tain a\n‘del by multiplying the waning tine, te number of GPUs used and an eunate of he sustained\n‘Single-pecsion floating-point capacity ofeach GPU ®\n62 Model Variations\n‘To evaluate the importance of diferent components ofthe Transformer, we varied our base model\n‘in dserent way, measuring the change in performance on English-German waslation on the\nevelopment et newstest2013. We ised bea serch as described inthe previous section, but no\n‘heckpoinaveraping. We present these ress in Table 3\nIn Table cows (A) we vary the number fate heads and he atetion ey and value dimensions,\n[Keeping the amount of computation constnt as described in Section 322 While single-head\naltetion s 09 BLEU worse than the best etn ual also drops ff with too many heads\n\n8",
          "type": "ocr_image",
          "page": 8,
          "confidence": 0.5,
          "source": "ocr_image",
          "metadata": {
            "length": 2931,
            "has_greek_letters": false,
            "has_superscript": false,
            "has_subscript": false,
            "has_fractions": true,
            "has_integrals": false,
            "has_summations": false,
            "complexity_score": 1.0,
            "source": "ocr_image"
          }
        },
        {
          "formula": "Table 3: Vision he Tasfome achieves re etl ta ofthe bse\n‘hve Altice fe Eno Getmn anton deepen se nese Led\nferia prworpee, carding or ye paienoding ad sald compared\nPeto popiice\n: vain | FPL BLEU jams\na\nTsir sz ae\nw toi is mea\nie 2D in Ba\nBout So 34\nie Sie 351\nz eit) 36\ni Pee?\n: is 3 8\n|\" 36 nz Shs 8\nithe i i ie deo ts\ntoot shot 8\n9 ih 32\na S07 ate\nfa i 3\n2 oo 467 253\noo |S 33\nw 492387\niE 48 AB\nIn Tale 3 sows), weohrve ht edicing the ation ky size darts mdel quay. Tis\n‘Sages ta cerning compat fst cay and at 2 ne sphsicaed emp\nitason hn dct gy Bebe We he oan intone Sand Dy aap\nIeper dls rte an dopou isl insvoving vein. now () weeps\n\"Ths poston! ecoing weed ptm eens a sare may nial\n‘Siow be mode\n7) Conclusion\nInti ork, we presen te Tansrme he fist sues ashton model asd ete on\n“oo: aig eeu aes mos anmonnd n eno decode acess 2\nites cto\nFor tat tas, th Tnsorner can be i sigan faster than cites based\nSnccet rcooluina ler On bth WAITS Engle Gean and WA 20\nEgtoenchanslaton ta. we ach a ate of he efor i us\n‘del uperots xe all pel eponedemembien\nWe ae exctedabou he fae of steno ed models apa apply hem tote asks. We\nPiatt eed he Tomtom opts ng pt ap ada hr ans and\n{Dincouu ca eae stenonmecarans en handle ge npas a ous\nShc's ages saan le Mang fenton Iss ser ana sca as fos\nTe cade we ised to win and ethute cut moe is salle at hetpe/ tub con/\nAcknonledgements We eget o Na Kalvene and Stephan Gout fri i\n°",
          "type": "ocr_image",
          "page": 9,
          "confidence": 0.5,
          "source": "ocr_image",
          "metadata": {
            "length": 1412,
            "has_greek_letters": false,
            "has_superscript": false,
            "has_subscript": false,
            "has_fractions": true,
            "has_integrals": false,
            "has_summations": false,
            "complexity_score": 0.30000000000000004,
            "source": "ocr_image"
          }
        },
        {
          "formula": "References\n\n[1} inumy Le Ba, Janie Ryan Kis, and Geoteey E Minton. Layer notmalization. Xi preprint\nrN 1607. 06450, 2016,\n\n[2} Danity Babdanu, Kyunghyun Cho, and Yosbua Beng. Neural machine wanslation by join\nFearing align and wanlte. CofR, abs! T409.0473, 2014\n\n[3} Denny Biz, Anna Goldie. Minh Thang Luong. and Quoc V. Le, Massive exploration of neural\n‘machin anslationachitoctres, CoRR, by! 70303906, 3017\n\n|i) ianpeng Cheng Li Dong nd Mirella Lapa. Loa sheer memoxy- networks for machine\nreaing arXiv preprint arXiv 1601 06788, 2016,\n\n[5] Kyunghyun Cho, Bart van Meutonboer Caglar Glcele,Fethi Boygates, Holgcr Schwenk,\nanu Yoshua Beno, eaming phrase representations using ra encode-decoer Tor staisial\n‘machine wansation, CoRR, abs/id06. 1078, 2014\n\n[6] Francois Chollet. Xception: Deep leaming with depthwise separable convlutons. arXiv\npreprint arXis:161002357, 2016\n\n17) Junyoung Chung, Caslar Gageve, Kyunghyun Cho and Yosbua Bengio. Empiical evaluation\nof gated recent neural etorks on Sequence modeling. CoRR, abW1412 3585, 2014\n\n[8) Jonas Gebring Michael Auli, David Granger, Denis Yaats and Yann N- Dauphin. Convo\nHnal sequence to sequence earning. arXiv preprint arXiv: 1705 0312202, 2017\n\n[9] Alex Graves. Generating sequences with recurrent neural networks. arXty preprint\nfrXi 13080850, 2013,\n\n{10} Kaiming He, Xiangyu Zhang. Shaoging Ren and Jian Sun. Deep residual learning for in\n‘ge recognition. It Proceedings ofthe IEEE Conference on Computer Vision and Patern\nRecognition, pages 770-798, 2016\n\n[ut] Sepp Hocteiter,Yoshua Bengio, Paolo Feascon, and Jurgen Sehmidhuber. Gradient Now in\nrectment net! the difficulty of leaning long-enn dependencies, 2001\n\n[12] Sepp Hochrster and Jurgen Schmidhuber, Long short-term memory. Nevral computation,\n(83:1735-1780, 1997\n\n[13] Rafal Jozefowiez, Oil Vinyas, Mike Schuster, Noam Shazoer. and Youghui Wo, Explocing\nthe linite of language modling.arXi preprint aX: 1602 02410, 2016\n\n[14] Laks Kase and ia Suskever. Neural GPUS lam algrithns. Ia ntemational Conference\n‘on Learning Representations (ICLR), 2016\n\n[US] Nal Kalehbreaes, Lasse Espholt, Kaen imonyan, Aura van den Oot. Alex Graves and Ko\n‘ay Kevukcuoghs, Neural machine translation a iea tie. ark preprint Xi: 1610. 200992,\nbun\n\n{16} Yoou Kim, Cat! Denton, Luong Hoang. and Altander M. Rush Structured astenton netwoks\nIn international Conferonce on Learning Represenations, 2017\n\n[U7] Diederik Kinga and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2018.\n\n[U8) Oletsit Kuchaiv and Bors Ginsburg. Factorization wicks for LSTM network. arXiv preprint\nsrXi: 170810722, 207,\n\n[19] Zhouhan Lin, Minwet Reng, Cicero Nogusea dos Santos, Mo Yu, Bing Xiang, Bowen\n‘Zhou, and Yeshua Bengio. A structed seleatemive sentence enbeing. arXs reprint\nrN 170803130, 2017,\n\n[20] Samy Bengio Lukasz Kaise. Can active memory replace attention? Ia Advances it Newral\nInformation Processing Systems, (NIPS), 2016\n\n0",
          "type": "ocr_image",
          "page": 10,
          "confidence": 0.5,
          "source": "ocr_image",
          "metadata": {
            "length": 2934,
            "has_greek_letters": false,
            "has_superscript": false,
            "has_subscript": false,
            "has_fractions": true,
            "has_integrals": false,
            "has_summations": false,
            "complexity_score": 0.4,
            "source": "ocr_image"
          }
        },
        {
          "formula": "[21] Minh-Thang Luons Hie Pham, and Crstopter D Manning. Este approaches to tention\nBased noual machine tanslaton. aX preprin arXiv 1508 04025, 2013\n\n[22] Ankur Parikh, Oscar Ticksuom, Dipanjan Das, and Jakob Usakoret. A decomposable aeation\n‘odel In Empirical Methods be Natural Language Processing, 2016\n\n[23] Romain Paulus, Calming Xiong. and Richard Soches. deep eafored model fo absactive\nSummatzation” aX preprint arte 708.0609, 2017\n\n[24] Orr Press and Lioe WolE, Using the output embedding 1 improve Language models. arXiv\nreprint arXiv 160805859, 2016.\n\n[25) Rico Sennch, Barty Hadlow and Alexandra Bich. Neural machine ansation of ee words\nwit subword wits arXi preprint ann 50807909, 2018.\n\n[26] Noum Shae, Azala Muhosein, Krzysztof Maziar2, Andy Davis, Quoc Le, Gooey Hinton,\nand eff Dean. Ourageously lage neural networks: The sparselygated mixtue-o-experis\nlayer aX reprint aie 701 06538, 2017\n\n[27] Naish Sivastava, Gooey E Hinton, Alex Krshevsy ya Sutskever, and Ruslan Suakutd\nov. Dropout: a snp way to prevent neural networks fom overiting. Journal of Machine\nLearing Research, 1S) 19291988, 2014\n\n[28) Sainbayar Sukbbautar, arthur slam. Jason Weston, and Rob Fergus. End-o-end memory\ntetworks, In C. Cortes, N-D. Lawrence, B.D, Les, M, Sugiyama, and R. Carnet, editrs,\n‘Advances b Newal Information Processing Systems 38, pages 2140-2448, Cuan Associates\nTne. 2015,\n\n[29] tiya Suskever Oriol Vinyals and Quoe VV Le. Sequence o sequence learing with neural\nnetworks. In Advances in Newel aformation Procesing Sytems, pages 3104-3112, 2014\n\n[30) Chistian Szegedy. Vincent Vanhoucke, Sergey Ioffe Jonathon Shlens and Zbigniew Wojna\nRethinking the inception rhitecture or computer Vision. CoRR, abs/I512. 00867, 2015,\n\n[31] Youghui Wu, Mike Schuster, Zhong Chen, Quoc V Le, Mohammad Novouzi, Wolfgang\nMachete. Maxim Krkun. Yuan Cao Qu Guo, Klaus Machows et Google's neural machine\ntranslation system: eiging the gap between bun and machine tansltion. aX reprint\nrN 1600,08144, 2016,\n\n[32] Jie Zhou, Ying Cao, Xuguang Wang. Peng Li and Wei Xu. Deep securent models with\n‘as-orwatd connections for neural machine warslaton. CoRR, abv 1606 04199, 2016,\n\nu",
          "type": "ocr_image",
          "page": 11,
          "confidence": 0.5,
          "source": "ocr_image",
          "metadata": {
            "length": 2167,
            "has_greek_letters": false,
            "has_superscript": false,
            "has_subscript": false,
            "has_fractions": true,
            "has_integrals": false,
            "has_summations": false,
            "complexity_score": 0.5,
            "source": "ocr_image"
          }
        }
      ],
      "statistics": {
        "total_formulas": 12,
        "text_source": 1,
        "pdf_source": 1,
        "ocr_source": 11,
        "avg_confidence": 0.48333333333333334,
        "complexity_distribution": {
          "simple": 2,
          "medium": 4,
          "complex": 6
        },
        "formula_types": {
          "fractions": 1,
          "ocr_image": 11
        }
      },
      "extraction_metadata": {
        "config": {
          "preserve_context": true,
          "context_chars": 50,
          "min_formula_length": 3,
          "max_formula_length": 1000,
          "extract_financial_symbols": true,
          "validate_latex": true
        },
        "patterns_used": [
          "inline_latex",
          "display_latex",
          "equation_env",
          "align_env",
          "eqnarray_env",
          "math_env",
          "displaymath_env",
          "bracket_inline",
          "bracket_display",
          "percentage",
          "currency",
          "scientific_notation",
          "ratios",
          "fractions",
          "greek_letters",
          "probability",
          "expectation",
          "variance",
          "correlation",
          "volatility",
          "returns",
          "derivatives"
        ]
      }
    },
    "images": [
      {
        "id": "vector_2_2432",
        "page": 3,
        "type": "vector_graphic",
        "format": "png",
        "size": [
          337,
          556
        ],
        "bbox": [
          442,
          185,
          779,
          741
        ],
        "quality_score": 0.5,
        "ocr_text": "Add & Norm Feed Forward Add & Norm AddleINorra Multi-Head Feed Attention Forward }_ Add & Norm Add& Nom Wated Multi-Head Multi-Head Attention Attention a c+ 3 al AD Pe ing Qe OLY En Input ‘Output Embedding Embedding",
        "is_chart": true,
        "chart_type": "unknown",
        "chart_confidence": 0.5,
        "contains_financial_content": false,
        "base64_thumbnail": "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",
        "metadata": {
          "source": "vector_graphic",
          "quality_score": 0.5,
          "chart_type": "unknown",
          "chart_confidence": 0.5
        },
        "extraction_timestamp": 1748282188.9463353,
        "is_financial_chart": false,
        "relevance_score": 0.5
      },
      {
        "id": "vector_3_3166",
        "page": 4,
        "type": "vector_graphic",
        "format": "png",
        "size": [
          226,
          290
        ],
        "bbox": [
          695,
          166,
          921,
          456
        ],
        "quality_score": 0.5,
        "ocr_text": "im Scaled Dot-Product ) } Attention p sD J (rea) {tinea {crea",
        "is_chart": true,
        "chart_type": "unknown",
        "chart_confidence": 0.5,
        "contains_financial_content": false,
        "base64_thumbnail": "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",
        "metadata": {
          "source": "vector_graphic",
          "quality_score": 0.5,
          "chart_type": "unknown",
          "chart_confidence": 0.5
        },
        "extraction_timestamp": 1748282188.9463391,
        "is_financial_chart": false,
        "relevance_score": 0.5
      },
      {
        "id": "vector_8_2665",
        "page": 9,
        "type": "vector_graphic",
        "format": "png",
        "size": [
          802,
          512
        ],
        "bbox": [
          216,
          258,
          1018,
          770
        ],
        "quality_score": 0.5,
        "ocr_text": "train PPL BLEU params base 49225865 T3512 512 529 249 w 4 128 128 5.00 25.5 16 32 32 491 258 3216 16 5.01 254 16 31625138 ®) sor B40 2 611237 36 4 5.19 253 50 8 488 255 80 © 256 32 32 575 245 28 1024 128 128 466 260 168 1024 512 254 53 4096 475262 90 00 377 246 02 495 25.5 ©) 0.0 467 253 02 547257 © 492 25.7 big 433 264 213",
        "is_chart": true,
        "chart_type": "unknown",
        "chart_confidence": 0.5,
        "contains_financial_content": false,
        "base64_thumbnail": "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",
        "metadata": {
          "source": "vector_graphic",
          "quality_score": 0.5,
          "chart_type": "unknown",
          "chart_confidence": 0.5
        },
        "extraction_timestamp": 1748282188.9463406,
        "is_financial_chart": false,
        "relevance_score": 0.5
      }
    ],
    "symbols": {
      "symbols_by_type": {
        "stock_ticker": [
          {
            "symbol": "N",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 270,
              "end": 271
            },
            "context": "earch\nllion@google.com\n\nAidan N. Gomez∗ †\nUniversity of Toron",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 1025,
              "end": 1029
            },
            "context": "rain. Our model achieves 28.4 BLEU on the WMT 2014 English-\nto-G",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "WMT",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 1037,
              "end": 1040
            },
            "context": "del achieves 28.4 BLEU on the WMT 2014 English-\nto-German trans",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 1156,
              "end": 1160
            },
            "context": "ncluding\nensembles, by over 2 BLEU. On the WMT 2014 English-to-F",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "WMT",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 1169,
              "end": 1172
            },
            "context": "mbles, by over 2 BLEU. On the WMT 2014 English-to-French transl",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 1272,
              "end": 1276
            },
            "context": "single-model state-of-the-art BLEU score of 41.0 after\ntraining ",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "NIPS",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 2893,
              "end": 2897
            },
            "context": "formation Processing Systems (NIPS 2017), Long Beach, CA, USA.\n\n",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "CA",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 2917,
              "end": 2919
            },
            "context": "tems (NIPS 2017), Long Beach, CA, USA.\n\n\fRecurrent models typi",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "USA",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 2921,
              "end": 2924
            },
            "context": " (NIPS 2017), Long Beach, CA, USA.\n\n\fRecurrent models typically",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "GPU",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 4524,
              "end": 4527
            },
            "context": "dation of the Extended Neural GPU\n[20], ByteNet [15] and ConvS2",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "N",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 7048,
              "end": 7049
            },
            "context": "der is composed of a stack of N = 6 identical layers. Each la",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "N",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 7738,
              "end": 7739
            },
            "context": "s also composed of a stack of N = 6 identical layers. In addi",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "Q",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 9373,
              "end": 9374
            },
            "context": "packed together\ninto a matrix Q. The keys and values are also",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "K",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 9435,
              "end": 9436
            },
            "context": "packed together into matrices K and V . We compute\nthe matrix",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "V",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 9441,
              "end": 9442
            },
            "context": " together into matrices K and V . We compute\nthe matrix of ou",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "Q",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 9493,
              "end": 9494
            },
            "context": "rix of outputs as:\n\nAttention(Q, K, V ) = softmax(\n\nQK T\n√\ndk",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "K",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 9496,
              "end": 9497
            },
            "context": " of outputs as:\n\nAttention(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "V",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 9499,
              "end": 9500
            },
            "context": " outputs as:\n\nAttention(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "QK",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 9515,
              "end": 9517
            },
            "context": "tention(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two ",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "T",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 9518,
              "end": 9519
            },
            "context": "tion(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two mo",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "V",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 9527,
              "end": 9528
            },
            "context": ", V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two most common",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "Q",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11455,
              "end": 11456
            },
            "context": "k = (cid:80)dk\n\n4\n\n\fMultiHead(Q, K, V ) = Concat(head1, ..., ",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "K",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11458,
              "end": 11459
            },
            "context": " (cid:80)dk\n\n4\n\n\fMultiHead(Q, K, V ) = Concat(head1, ..., hea",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "V",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11461,
              "end": 11462
            },
            "context": "id:80)dk\n\n4\n\n\fMultiHead(Q, K, V ) = Concat(head1, ..., headh)",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "W",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11492,
              "end": 11493
            },
            "context": " ) = Concat(head1, ..., headh)W O\n\nwhere headi = Attention(QW",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11494,
              "end": 11495
            },
            "context": " = Concat(head1, ..., headh)W O\n\nwhere headi = Attention(QW Q",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "QW",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11521,
              "end": 11523
            },
            "context": ")W O\n\nwhere headi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\n",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "Q",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11524,
              "end": 11525
            },
            "context": "O\n\nwhere headi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWh",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "KW",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11531,
              "end": 11533
            },
            "context": "e headi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the ",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "K",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11534,
              "end": 11535
            },
            "context": "eadi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the pr",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "V",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11541,
              "end": 11542
            },
            "context": "Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the projectio",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "W",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11543,
              "end": 11544
            },
            "context": "tention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the projections",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "V",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11545,
              "end": 11546
            },
            "context": "ntion(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the projections a",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "W",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11598,
              "end": 11599
            },
            "context": "ctions are parameter matrices W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "Q",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11600,
              "end": 11601
            },
            "context": "ions are parameter matrices W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈ R",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "W",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11606,
              "end": 11607
            },
            "context": "re parameter matrices W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈ Rdmodel",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11608,
              "end": 11609
            },
            "context": " parameter matrices W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈ Rdmodel×d",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "W",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11643,
              "end": 11644
            },
            "context": "hdv×dmodel.\n\ni ∈ Rdmodel×dk , W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ ",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "K",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11645,
              "end": 11646
            },
            "context": "v×dmodel.\n\ni ∈ Rdmodel×dk , W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ Rd",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "W",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11665,
              "end": 11666
            },
            "context": "el×dk , W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ Rdmodel×dv\n\nIn this wo",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "V",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 11667,
              "end": 11668
            },
            "context": "×dk , W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ Rdmodel×dv\n\nIn this work",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "FFN",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 13479,
              "end": 13482
            },
            "context": " ReLU activation in between.\n\nFFN(x) = max(0, xW1 + b1)W2 + b2\n",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15076,
              "end": 15077
            },
            "context": "\nSelf-Attention (restricted)\n\nO(n2 · d)\nO(n · d2)\nO(k · n · d",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15086,
              "end": 15087
            },
            "context": "ntion (restricted)\n\nO(n2 · d)\nO(n · d2)\nO(k · n · d2)\nO(r · n",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15096,
              "end": 15097
            },
            "context": "tricted)\n\nO(n2 · d)\nO(n · d2)\nO(k · n · d2)\nO(r · n · d)\n\nSeq",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15110,
              "end": 15111
            },
            "context": " · d)\nO(n · d2)\nO(k · n · d2)\nO(r · n · d)\n\nSequential Maximu",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15166,
              "end": 15167
            },
            "context": "aximum Path Length\nOperations\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\n",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15171,
              "end": 15172
            },
            "context": "m Path Length\nOperations\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(log",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15176,
              "end": 15177
            },
            "context": "h Length\nOperations\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15181,
              "end": 15182
            },
            "context": "gth\nOperations\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))\nO(n/",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15187,
              "end": 15188
            },
            "context": "erations\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))\nO(n/r)\n\nbo",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15192,
              "end": 15193
            },
            "context": "ons\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))\nO(n/r)\n\nbottoms",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15197,
              "end": 15198
            },
            "context": "(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))\nO(n/r)\n\nbottoms of t",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15208,
              "end": 15209
            },
            "context": "1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))\nO(n/r)\n\nbottoms of the encoder ",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "P",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15510,
              "end": 15511
            },
            "context": "ns of different frequencies:\n\nP E(pos,2i) = sin(pos/100002i/d",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "E",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15512,
              "end": 15513
            },
            "context": " of different frequencies:\n\nP E(pos,2i) = sin(pos/100002i/dmo",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "P",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15548,
              "end": 15549
            },
            "context": "2i) = sin(pos/100002i/dmodel)\nP E(pos,2i+1) = cos(pos/100002i",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "E",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15550,
              "end": 15551
            },
            "context": ") = sin(pos/100002i/dmodel)\nP E(pos,2i+1) = cos(pos/100002i/d",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "P",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15935,
              "end": 15936
            },
            "context": " since for any ﬁxed offset k, P Epos+k can be represented as ",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "P",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 15987,
              "end": 15988
            },
            "context": "ented as a linear function of\nP Epos.\n\nWe also experimented w",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "E",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 16155,
              "end": 16156
            },
            "context": "cal results (see Table 3 row (E)). We chose the sinusoidal ve",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 17713,
              "end": 17714
            },
            "context": "as a recurrent layer requires O(n) sequential operations. In ",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 18370,
              "end": 18371
            },
            "context": "se the maximum\npath length to O(n/r). We plan to investigate ",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "A",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 18440,
              "end": 18441
            },
            "context": "oach further in future work.\n\nA single convolutional layer wi",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 18580,
              "end": 18581
            },
            "context": " Doing so requires a stack of O(n/k) convolutional layers in ",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 18646,
              "end": 18647
            },
            "context": "ase of contiguous kernels,\nor O(logk(n)) in the case of dilat",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "O",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 18953,
              "end": 18954
            },
            "context": "e complexity\nconsiderably, to O(k · n · d + n · d2). Even wit",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "WMT",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 19653,
              "end": 19656
            },
            "context": "g\n\nWe trained on the standard WMT 2014 English-German dataset c",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "WMT",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 19906,
              "end": 19909
            },
            "context": " used the signiﬁcantly larger WMT\n2014 English-French dataset c",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 21552,
              "end": 21556
            },
            "context": "e Transformer achieves better BLEU scores than previous state-of",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "GNMT",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 21748,
              "end": 21752
            },
            "context": "t [15]\nDeep-Att + PosUnk [32]\nGNMT + RL [31]\nConvS2S [8]\nMoE [26",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "RL",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 21755,
              "end": 21757
            },
            "context": "Deep-Att + PosUnk [32]\nGNMT + RL [31]\nConvS2S [8]\nMoE [26]\nDee",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "GNMT",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 21816,
              "end": 21820
            },
            "context": "ep-Att + PosUnk Ensemble [32]\nGNMT + RL Ensemble [31]\nConvS2S En",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "RL",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 21823,
              "end": 21825
            },
            "context": "+ PosUnk Ensemble [32]\nGNMT + RL Ensemble [31]\nConvS2S Ensembl",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 21905,
              "end": 21909
            },
            "context": "ase model)\nTransformer (big)\n\nBLEU\n\nTraining Cost (FLOPs)\n\nEN-DE",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "EN",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 21934,
              "end": 21936
            },
            "context": "\nBLEU\n\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "DE",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 21937,
              "end": 21939
            },
            "context": "EU\n\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "EN",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 21940,
              "end": 21942
            },
            "context": "\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03\n\n2",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "FR",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 21943,
              "end": 21945
            },
            "context": "aining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03\n\n26.3",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "EN",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 22045,
              "end": 22047
            },
            "context": "6\n40.4\n41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "DE",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 22048,
              "end": 22050
            },
            "context": "0.4\n41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "EN",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 22052,
              "end": 22054
            },
            "context": "41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018\n2.0",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "FR",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 22055,
              "end": 22057
            },
            "context": "16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018\n2.0 · ",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 22398,
              "end": 22402
            },
            "context": "re, but improves accuracy and BLEU score.\n\n6 Results\n\n6.1 Machin",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "WMT",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 22454,
              "end": 22457
            },
            "context": "1 Machine Translation\n\nOn the WMT 2014 English-to-German transl",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 22643,
              "end": 22647
            },
            "context": "g ensembles) by more than 2.0\nBLEU, establishing a new state-of-",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 22685,
              "end": 22689
            },
            "context": "ishing a new state-of-the-art BLEU score of 28.4. The conﬁgurati",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "WMT",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 22970,
              "end": 22973
            },
            "context": "e competitive models.\n\nOn the WMT 2014 English-to-French transl",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 23040,
              "end": 23044
            },
            "context": "ask, our big model achieves a BLEU score of 41.0,\noutperforming ",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "GPU",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 24110,
              "end": 24113
            },
            "context": "oating-point capacity of each GPU 5.\n\n6.2 Model Variations\n\nTo ",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "A",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 24504,
              "end": 24505
            },
            "context": "in Table 3.\n\nIn Table 3 rows (A), we vary the number of atten",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 24700,
              "end": 24704
            },
            "context": " single-head\nattention is 0.9 BLEU worse than the best setting, ",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "N",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 25199,
              "end": 25200
            },
            "context": "ed to\nper-word perplexities.\n\nN dmodel\n\ndff\n\nbase\n\n6\n\n512\n\n20",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "A",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 25459,
              "end": 25460
            },
            "context": "ids\n\n6\n\n1024\n\n4096\n\n16\n\n0.3\n\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "B",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 25464,
              "end": 25465
            },
            "context": "6\n\n1024\n\n4096\n\n16\n\n0.3\n\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrai",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "C",
            "type": "stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 25469,
              "end": 25470
            },
            "context": "24\n\n4096\n\n16\n\n0.3\n\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrain\nste",
            "confidence": 1.0,
            "metadata": {
              "type": "stock_ticker",
              "verified": true
            }
          },
          {
            "symbol": "D",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 25474,
              "end": 25475
            },
            "context": "096\n\n16\n\n0.3\n\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrain\nsteps\n(d",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "E",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 25479,
              "end": 25480
            },
            "context": "16\n\n0.3\n\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrain\nsteps\n(dev)\n1",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "PPL",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 25487,
              "end": 25490
            },
            "context": "\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrain\nsteps\n(dev)\n100K 4.92\n5",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 25620,
              "end": 25624
            },
            "context": ".95\n4.67\n5.47\n4.92\n300K 4.33\n\nBLEU params\n×106\n(dev)\n25.8\n65\n24.",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "B",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 25798,
              "end": 25799
            },
            "context": "\n53\n90\n\n213\n\nIn Table 3 rows (B), we observe that reducing th",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "C",
            "type": "stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 26047,
              "end": 26048
            },
            "context": ". We further observe in rows (C) and (D) that, as expected,\nb",
            "confidence": 1.0,
            "metadata": {
              "type": "stock_ticker",
              "verified": true
            }
          },
          {
            "symbol": "D",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 26055,
              "end": 26056
            },
            "context": "ther observe in rows (C) and (D) that, as expected,\nbigger mo",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "E",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 26164,
              "end": 26165
            },
            "context": "avoiding over-ﬁtting. In row (E) we replace our\nsinusoidal po",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "WMT",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 26697,
              "end": 26700
            },
            "context": "convolutional layers. On both WMT 2014 English-to-German and WM",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "WMT",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 26728,
              "end": 26731
            },
            "context": "MT 2014 English-to-German and WMT 2014\nEnglish-to-French transl",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "E",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 27608,
              "end": 27609
            },
            "context": "amie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. ",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "V",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 27893,
              "end": 27894
            },
            "context": "e, Minh-Thang Luong, and Quoc V. Le. Massive exploration of n",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "N",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 28745,
              "end": 28746
            },
            "context": "ngier, Denis Yarats, and Yann N. Dauphin. Convolu-\n\ntional se",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "IEEE",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 29088,
              "end": 29092
            },
            "context": "nition. In Proceedings of the IEEE Conference on Computer Vision",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "ICLR",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 29744,
              "end": 29748
            },
            "context": "\non Learning Representations (ICLR), 2016.\n\n[15] Nal Kalchbrenne",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "M",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 30011,
              "end": 30012
            },
            "context": "n, Luong Hoang, and Alexander M. Rush. Structured attention n",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "A",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 30157,
              "end": 30158
            },
            "context": "ik Kingma and Jimmy Ba. Adam: A method for stochastic optimiz",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "ICLR",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 30198,
              "end": 30202
            },
            "context": "r stochastic optimization. In ICLR, 2015.\n\n[18] Oleksii Kuchaiev",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "LSTM",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 30278,
              "end": 30282
            },
            "context": "urg. Factorization tricks for LSTM networks. arXiv preprint\n\narX",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "A",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 30443,
              "end": 30444
            },
            "context": "owen\nZhou, and Yoshua Bengio. A structured self-attentive sen",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "NIPS",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 30656,
              "end": 30660
            },
            "context": "ormation Processing Systems, (NIPS), 2016.\n\n10\n\n\f[21] Minh-Thang",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "D",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 30725,
              "end": 30726
            },
            "context": "g, Hieu Pham, and Christopher D Manning. Effective approaches",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "A",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 30917,
              "end": 30918
            },
            "context": "jan Das, and Jakob Uszkoreit. A decomposable attention\n\nmodel",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "A",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 31065,
              "end": 31066
            },
            "context": "ng Xiong, and Richard Socher. A deep reinforced model for abs",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "E",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 31708,
              "end": 31709
            },
            "context": "] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "C",
            "type": "stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 32009,
              "end": 32010
            },
            "context": "nd-to-end memory\nnetworks. In C. Cortes, N. D. Lawrence, D. D",
            "confidence": 1.0,
            "metadata": {
              "type": "stock_ticker",
              "verified": true
            }
          },
          {
            "symbol": "N",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 32020,
              "end": 32021
            },
            "context": "emory\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. S",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "D",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 32023,
              "end": 32024
            },
            "context": "ry\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugi",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "D",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 32036,
              "end": 32037
            },
            "context": "In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. ",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "D",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 32039,
              "end": 32040
            },
            "context": "C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Gar",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "M",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 32047,
              "end": 32048
            },
            "context": "s, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, ed",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "R",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 32064,
              "end": 32065
            },
            "context": ", D. D. Lee, M. Sugiyama, and R. Garnett, editors,\nAdvances i",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "VV",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 32233,
              "end": 32235
            },
            "context": "ever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence lear",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "V",
            "type": "potential_stock_ticker",
            "pattern": "stock_ticker",
            "position": {
              "start": 32604,
              "end": 32605
            },
            "context": " Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgan",
            "confidence": 0.7,
            "metadata": {
              "needs_validation": true
            }
          }
        ],
        "crypto_symbol": [
          {
            "symbol": "BLEU",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 1025,
              "end": 1029
            },
            "context": "rain. Our model achieves 28.4 BLEU on the WMT 2014 English-\nto-G",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "WMT",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 1037,
              "end": 1040
            },
            "context": "del achieves 28.4 BLEU on the WMT 2014 English-\nto-German trans",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 1156,
              "end": 1160
            },
            "context": "ncluding\nensembles, by over 2 BLEU. On the WMT 2014 English-to-F",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "WMT",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 1169,
              "end": 1172
            },
            "context": "mbles, by over 2 BLEU. On the WMT 2014 English-to-French transl",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 1272,
              "end": 1276
            },
            "context": "single-model state-of-the-art BLEU score of 41.0 after\ntraining ",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "NIPS",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 2893,
              "end": 2897
            },
            "context": "formation Processing Systems (NIPS 2017), Long Beach, CA, USA.\n\n",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "CA",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 2917,
              "end": 2919
            },
            "context": "tems (NIPS 2017), Long Beach, CA, USA.\n\n\fRecurrent models typi",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "USA",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 2921,
              "end": 2924
            },
            "context": " (NIPS 2017), Long Beach, CA, USA.\n\n\fRecurrent models typically",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "GPU",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 4524,
              "end": 4527
            },
            "context": "dation of the Extended Neural GPU\n[20], ByteNet [15] and ConvS2",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "QK",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 9515,
              "end": 9517
            },
            "context": "tention(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two ",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "QW",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 11521,
              "end": 11523
            },
            "context": ")W O\n\nwhere headi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\n",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "KW",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 11531,
              "end": 11533
            },
            "context": "e headi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the ",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "FFN",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 13479,
              "end": 13482
            },
            "context": " ReLU activation in between.\n\nFFN(x) = max(0, xW1 + b1)W2 + b2\n",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "WMT",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 19653,
              "end": 19656
            },
            "context": "g\n\nWe trained on the standard WMT 2014 English-German dataset c",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "WMT",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 19906,
              "end": 19909
            },
            "context": " used the signiﬁcantly larger WMT\n2014 English-French dataset c",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "NVIDIA",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 20289,
              "end": 20295
            },
            "context": " models on one machine with 8 NVIDIA P100 GPUs. For our base model",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 21552,
              "end": 21556
            },
            "context": "e Transformer achieves better BLEU scores than previous state-of",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "GNMT",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 21748,
              "end": 21752
            },
            "context": "t [15]\nDeep-Att + PosUnk [32]\nGNMT + RL [31]\nConvS2S [8]\nMoE [26",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "RL",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 21755,
              "end": 21757
            },
            "context": "Deep-Att + PosUnk [32]\nGNMT + RL [31]\nConvS2S [8]\nMoE [26]\nDee",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "GNMT",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 21816,
              "end": 21820
            },
            "context": "ep-Att + PosUnk Ensemble [32]\nGNMT + RL Ensemble [31]\nConvS2S En",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "RL",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 21823,
              "end": 21825
            },
            "context": "+ PosUnk Ensemble [32]\nGNMT + RL Ensemble [31]\nConvS2S Ensembl",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 21905,
              "end": 21909
            },
            "context": "ase model)\nTransformer (big)\n\nBLEU\n\nTraining Cost (FLOPs)\n\nEN-DE",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "EN",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 21934,
              "end": 21936
            },
            "context": "\nBLEU\n\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "DE",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 21937,
              "end": 21939
            },
            "context": "EU\n\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "EN",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 21940,
              "end": 21942
            },
            "context": "\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03\n\n2",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "FR",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 21943,
              "end": 21945
            },
            "context": "aining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03\n\n26.3",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "EN",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 22045,
              "end": 22047
            },
            "context": "6\n40.4\n41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "DE",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 22048,
              "end": 22050
            },
            "context": "0.4\n41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "EN",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 22052,
              "end": 22054
            },
            "context": "41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018\n2.0",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "FR",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 22055,
              "end": 22057
            },
            "context": "16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018\n2.0 · ",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 22398,
              "end": 22402
            },
            "context": "re, but improves accuracy and BLEU score.\n\n6 Results\n\n6.1 Machin",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "WMT",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 22454,
              "end": 22457
            },
            "context": "1 Machine Translation\n\nOn the WMT 2014 English-to-German transl",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 22643,
              "end": 22647
            },
            "context": "g ensembles) by more than 2.0\nBLEU, establishing a new state-of-",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 22685,
              "end": 22689
            },
            "context": "ishing a new state-of-the-art BLEU score of 28.4. The conﬁgurati",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "WMT",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 22970,
              "end": 22973
            },
            "context": "e competitive models.\n\nOn the WMT 2014 English-to-French transl",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 23040,
              "end": 23044
            },
            "context": "ask, our big model achieves a BLEU score of 41.0,\noutperforming ",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "GPU",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 24110,
              "end": 24113
            },
            "context": "oating-point capacity of each GPU 5.\n\n6.2 Model Variations\n\nTo ",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 24700,
              "end": 24704
            },
            "context": " single-head\nattention is 0.9 BLEU worse than the best setting, ",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "TFLOPS",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 24820,
              "end": 24826
            },
            "context": "lues of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, r",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "PPL",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 25487,
              "end": 25490
            },
            "context": "\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrain\nsteps\n(dev)\n100K 4.92\n5",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "BLEU",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 25620,
              "end": 25624
            },
            "context": ".95\n4.67\n5.47\n4.92\n300K 4.33\n\nBLEU params\n×106\n(dev)\n25.8\n65\n24.",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "WMT",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 26697,
              "end": 26700
            },
            "context": "convolutional layers. On both WMT 2014 English-to-German and WM",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "WMT",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 26728,
              "end": 26731
            },
            "context": "MT 2014 English-to-German and WMT 2014\nEnglish-to-French transl",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "IEEE",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 29088,
              "end": 29092
            },
            "context": "nition. In Proceedings of the IEEE Conference on Computer Vision",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "ICLR",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 29744,
              "end": 29748
            },
            "context": "\non Learning Representations (ICLR), 2016.\n\n[15] Nal Kalchbrenne",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "ICLR",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 30198,
              "end": 30202
            },
            "context": "r stochastic optimization. In ICLR, 2015.\n\n[18] Oleksii Kuchaiev",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "LSTM",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 30278,
              "end": 30282
            },
            "context": "urg. Factorization tricks for LSTM networks. arXiv preprint\n\narX",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "NIPS",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 30656,
              "end": 30660
            },
            "context": "ormation Processing Systems, (NIPS), 2016.\n\n10\n\n\f[21] Minh-Thang",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          },
          {
            "symbol": "VV",
            "type": "potential_crypto_symbol",
            "pattern": "crypto_symbol",
            "position": {
              "start": 32233,
              "end": 32235
            },
            "context": "ever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence lear",
            "confidence": 0.6,
            "metadata": {
              "needs_validation": true
            }
          }
        ],
        "greek_letter": [
          {
            "symbol": "π",
            "type": "greek_letter",
            "pattern": "greek_letter",
            "position": {
              "start": 15768,
              "end": 15769
            },
            "context": "a geometric progression from 2π to 10000 · 2π. We\nchose this ",
            "confidence": 1.0,
            "metadata": {
              "type": "greek_letter",
              "name": "pi"
            }
          },
          {
            "symbol": "π",
            "type": "greek_letter",
            "pattern": "greek_letter",
            "position": {
              "start": 15782,
              "end": 15783
            },
            "context": "ogression from 2π to 10000 · 2π. We\nchose this function becau",
            "confidence": 1.0,
            "metadata": {
              "type": "greek_letter",
              "name": "pi"
            }
          },
          {
            "symbol": "β",
            "type": "greek_letter",
            "pattern": "greek_letter",
            "position": {
              "start": 20697,
              "end": 20698
            },
            "context": " the Adam optimizer [17] with β1 = 0.9, β2 = 0.98 and (cid:15",
            "confidence": 1.0,
            "metadata": {
              "type": "greek_letter",
              "name": "beta"
            }
          },
          {
            "symbol": "β",
            "type": "greek_letter",
            "pattern": "greek_letter",
            "position": {
              "start": 20707,
              "end": 20708
            },
            "context": "optimizer [17] with β1 = 0.9, β2 = 0.98 and (cid:15) = 10−9. ",
            "confidence": 1.0,
            "metadata": {
              "type": "greek_letter",
              "name": "beta"
            }
          },
          {
            "symbol": "α",
            "type": "greek_letter",
            "pattern": "greek_letter",
            "position": {
              "start": 23553,
              "end": 23554
            },
            "context": " size of 4 and length penalty α = 0.6 [31]. These hyperparame",
            "confidence": 1.0,
            "metadata": {
              "type": "greek_letter",
              "name": "alpha"
            }
          }
        ],
        "mathematical_symbol": [
          {
            "symbol": "√",
            "type": "mathematical",
            "pattern": "mathematical_symbol",
            "position": {
              "start": 9194,
              "end": 9195
            },
            "context": "keys, divide each by\nvalues.\n\n√\n\ndk, and apply a softmax func",
            "confidence": 1.0,
            "metadata": {
              "type": "mathematical",
              "name": "sqrt"
            }
          },
          {
            "symbol": "√",
            "type": "mathematical",
            "pattern": "mathematical_symbol",
            "position": {
              "start": 9520,
              "end": 9521
            },
            "context": "on(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two most",
            "confidence": 1.0,
            "metadata": {
              "type": "mathematical",
              "name": "sqrt"
            }
          },
          {
            "symbol": "√",
            "type": "mathematical",
            "pattern": "mathematical_symbol",
            "position": {
              "start": 9536,
              "end": 9537
            },
            "context": "oftmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two most commonly used a",
            "confidence": 1.0,
            "metadata": {
              "type": "mathematical",
              "name": "sqrt"
            }
          },
          {
            "symbol": "√",
            "type": "mathematical",
            "pattern": "mathematical_symbol",
            "position": {
              "start": 10459,
              "end": 10460
            },
            "context": "we scale the dot products by 1√\ndk\n\n.\n\n3.2.2 Multi-Head Atten",
            "confidence": 1.0,
            "metadata": {
              "type": "mathematical",
              "name": "sqrt"
            }
          },
          {
            "symbol": "∈",
            "type": "mathematical",
            "pattern": "mathematical_symbol",
            "position": {
              "start": 11610,
              "end": 11611
            },
            "context": "arameter matrices W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈ Rdmodel×dk ",
            "confidence": 1.0,
            "metadata": {
              "type": "mathematical",
              "name": "element_of"
            }
          },
          {
            "symbol": "∈",
            "type": "mathematical",
            "pattern": "mathematical_symbol",
            "position": {
              "start": 11628,
              "end": 11629
            },
            "context": "W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈ Rdmodel×dk , W K\n\ni ∈ Rdmodel",
            "confidence": 1.0,
            "metadata": {
              "type": "mathematical",
              "name": "element_of"
            }
          },
          {
            "symbol": "∈",
            "type": "mathematical",
            "pattern": "mathematical_symbol",
            "position": {
              "start": 11650,
              "end": 11651
            },
            "context": "del.\n\ni ∈ Rdmodel×dk , W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ Rdmodel",
            "confidence": 1.0,
            "metadata": {
              "type": "mathematical",
              "name": "element_of"
            }
          },
          {
            "symbol": "∈",
            "type": "mathematical",
            "pattern": "mathematical_symbol",
            "position": {
              "start": 11672,
              "end": 11673
            },
            "context": " W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ Rdmodel×dv\n\nIn this work we e",
            "confidence": 1.0,
            "metadata": {
              "type": "mathematical",
              "name": "element_of"
            }
          },
          {
            "symbol": "∞",
            "type": "mathematical",
            "pattern": "mathematical_symbol",
            "position": {
              "start": 13066,
              "end": 13067
            },
            "context": "n by masking out (setting to −∞) all values in the input\nof t",
            "confidence": 1.0,
            "metadata": {
              "type": "mathematical",
              "name": "infinity"
            }
          },
          {
            "symbol": "√",
            "type": "mathematical",
            "pattern": "mathematical_symbol",
            "position": {
              "start": 14353,
              "end": 14354
            },
            "context": "we multiply those weights by\n\n√\n\n3.5 Positional Encoding\n\nSin",
            "confidence": 1.0,
            "metadata": {
              "type": "mathematical",
              "name": "sqrt"
            }
          },
          {
            "symbol": "∈",
            "type": "mathematical",
            "pattern": "mathematical_symbol",
            "position": {
              "start": 16601,
              "end": 16602
            },
            "context": "th (z1, ..., zn), with xi, zi ∈ Rd, such as a hidden\nlayer in",
            "confidence": 1.0,
            "metadata": {
              "type": "mathematical",
              "name": "element_of"
            }
          }
        ]
      },
      "symbols_by_position": [
        {
          "symbol": "N",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 270,
            "end": 271
          },
          "context": "earch\nllion@google.com\n\nAidan N. Gomez∗ †\nUniversity of Toron",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 1025,
            "end": 1029
          },
          "context": "rain. Our model achieves 28.4 BLEU on the WMT 2014 English-\nto-G",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 1025,
            "end": 1029
          },
          "context": "rain. Our model achieves 28.4 BLEU on the WMT 2014 English-\nto-G",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "WMT",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 1037,
            "end": 1040
          },
          "context": "del achieves 28.4 BLEU on the WMT 2014 English-\nto-German trans",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "WMT",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 1037,
            "end": 1040
          },
          "context": "del achieves 28.4 BLEU on the WMT 2014 English-\nto-German trans",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 1156,
            "end": 1160
          },
          "context": "ncluding\nensembles, by over 2 BLEU. On the WMT 2014 English-to-F",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 1156,
            "end": 1160
          },
          "context": "ncluding\nensembles, by over 2 BLEU. On the WMT 2014 English-to-F",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "WMT",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 1169,
            "end": 1172
          },
          "context": "mbles, by over 2 BLEU. On the WMT 2014 English-to-French transl",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "WMT",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 1169,
            "end": 1172
          },
          "context": "mbles, by over 2 BLEU. On the WMT 2014 English-to-French transl",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 1272,
            "end": 1276
          },
          "context": "single-model state-of-the-art BLEU score of 41.0 after\ntraining ",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 1272,
            "end": 1276
          },
          "context": "single-model state-of-the-art BLEU score of 41.0 after\ntraining ",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "NIPS",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 2893,
            "end": 2897
          },
          "context": "formation Processing Systems (NIPS 2017), Long Beach, CA, USA.\n\n",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "NIPS",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 2893,
            "end": 2897
          },
          "context": "formation Processing Systems (NIPS 2017), Long Beach, CA, USA.\n\n",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "CA",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 2917,
            "end": 2919
          },
          "context": "tems (NIPS 2017), Long Beach, CA, USA.\n\n\fRecurrent models typi",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "CA",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 2917,
            "end": 2919
          },
          "context": "tems (NIPS 2017), Long Beach, CA, USA.\n\n\fRecurrent models typi",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "USA",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 2921,
            "end": 2924
          },
          "context": " (NIPS 2017), Long Beach, CA, USA.\n\n\fRecurrent models typically",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "USA",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 2921,
            "end": 2924
          },
          "context": " (NIPS 2017), Long Beach, CA, USA.\n\n\fRecurrent models typically",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "GPU",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 4524,
            "end": 4527
          },
          "context": "dation of the Extended Neural GPU\n[20], ByteNet [15] and ConvS2",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "GPU",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 4524,
            "end": 4527
          },
          "context": "dation of the Extended Neural GPU\n[20], ByteNet [15] and ConvS2",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "N",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 7048,
            "end": 7049
          },
          "context": "der is composed of a stack of N = 6 identical layers. Each la",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "N",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 7738,
            "end": 7739
          },
          "context": "s also composed of a stack of N = 6 identical layers. In addi",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "√",
          "type": "mathematical",
          "pattern": "mathematical_symbol",
          "position": {
            "start": 9194,
            "end": 9195
          },
          "context": "keys, divide each by\nvalues.\n\n√\n\ndk, and apply a softmax func",
          "confidence": 1.0,
          "metadata": {
            "type": "mathematical",
            "name": "sqrt"
          }
        },
        {
          "symbol": "Q",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 9373,
            "end": 9374
          },
          "context": "packed together\ninto a matrix Q. The keys and values are also",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "K",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 9435,
            "end": 9436
          },
          "context": "packed together into matrices K and V . We compute\nthe matrix",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "V",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 9441,
            "end": 9442
          },
          "context": " together into matrices K and V . We compute\nthe matrix of ou",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "Q",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 9493,
            "end": 9494
          },
          "context": "rix of outputs as:\n\nAttention(Q, K, V ) = softmax(\n\nQK T\n√\ndk",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "K",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 9496,
            "end": 9497
          },
          "context": " of outputs as:\n\nAttention(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "V",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 9499,
            "end": 9500
          },
          "context": " outputs as:\n\nAttention(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "QK",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 9515,
            "end": 9517
          },
          "context": "tention(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two ",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "QK",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 9515,
            "end": 9517
          },
          "context": "tention(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two ",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "T",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 9518,
            "end": 9519
          },
          "context": "tion(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two mo",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "√",
          "type": "mathematical",
          "pattern": "mathematical_symbol",
          "position": {
            "start": 9520,
            "end": 9521
          },
          "context": "on(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two most",
          "confidence": 1.0,
          "metadata": {
            "type": "mathematical",
            "name": "sqrt"
          }
        },
        {
          "symbol": "V",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 9527,
            "end": 9528
          },
          "context": ", V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two most common",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "√",
          "type": "mathematical",
          "pattern": "mathematical_symbol",
          "position": {
            "start": 9536,
            "end": 9537
          },
          "context": "oftmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two most commonly used a",
          "confidence": 1.0,
          "metadata": {
            "type": "mathematical",
            "name": "sqrt"
          }
        },
        {
          "symbol": "√",
          "type": "mathematical",
          "pattern": "mathematical_symbol",
          "position": {
            "start": 10459,
            "end": 10460
          },
          "context": "we scale the dot products by 1√\ndk\n\n.\n\n3.2.2 Multi-Head Atten",
          "confidence": 1.0,
          "metadata": {
            "type": "mathematical",
            "name": "sqrt"
          }
        },
        {
          "symbol": "Q",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11455,
            "end": 11456
          },
          "context": "k = (cid:80)dk\n\n4\n\n\fMultiHead(Q, K, V ) = Concat(head1, ..., ",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "K",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11458,
            "end": 11459
          },
          "context": " (cid:80)dk\n\n4\n\n\fMultiHead(Q, K, V ) = Concat(head1, ..., hea",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "V",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11461,
            "end": 11462
          },
          "context": "id:80)dk\n\n4\n\n\fMultiHead(Q, K, V ) = Concat(head1, ..., headh)",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "W",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11492,
            "end": 11493
          },
          "context": " ) = Concat(head1, ..., headh)W O\n\nwhere headi = Attention(QW",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11494,
            "end": 11495
          },
          "context": " = Concat(head1, ..., headh)W O\n\nwhere headi = Attention(QW Q",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "QW",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11521,
            "end": 11523
          },
          "context": ")W O\n\nwhere headi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\n",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "QW",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 11521,
            "end": 11523
          },
          "context": ")W O\n\nwhere headi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\n",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "Q",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11524,
            "end": 11525
          },
          "context": "O\n\nwhere headi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWh",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "KW",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11531,
            "end": 11533
          },
          "context": "e headi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the ",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "KW",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 11531,
            "end": 11533
          },
          "context": "e headi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the ",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "K",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11534,
            "end": 11535
          },
          "context": "eadi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the pr",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "V",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11541,
            "end": 11542
          },
          "context": "Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the projectio",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "W",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11543,
            "end": 11544
          },
          "context": "tention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the projections",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "V",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11545,
            "end": 11546
          },
          "context": "ntion(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the projections a",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "W",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11598,
            "end": 11599
          },
          "context": "ctions are parameter matrices W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "Q",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11600,
            "end": 11601
          },
          "context": "ions are parameter matrices W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈ R",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "W",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11606,
            "end": 11607
          },
          "context": "re parameter matrices W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈ Rdmodel",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11608,
            "end": 11609
          },
          "context": " parameter matrices W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈ Rdmodel×d",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "∈",
          "type": "mathematical",
          "pattern": "mathematical_symbol",
          "position": {
            "start": 11610,
            "end": 11611
          },
          "context": "arameter matrices W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈ Rdmodel×dk ",
          "confidence": 1.0,
          "metadata": {
            "type": "mathematical",
            "name": "element_of"
          }
        },
        {
          "symbol": "∈",
          "type": "mathematical",
          "pattern": "mathematical_symbol",
          "position": {
            "start": 11628,
            "end": 11629
          },
          "context": "W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈ Rdmodel×dk , W K\n\ni ∈ Rdmodel",
          "confidence": 1.0,
          "metadata": {
            "type": "mathematical",
            "name": "element_of"
          }
        },
        {
          "symbol": "W",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11643,
            "end": 11644
          },
          "context": "hdv×dmodel.\n\ni ∈ Rdmodel×dk , W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ ",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "K",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11645,
            "end": 11646
          },
          "context": "v×dmodel.\n\ni ∈ Rdmodel×dk , W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ Rd",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "∈",
          "type": "mathematical",
          "pattern": "mathematical_symbol",
          "position": {
            "start": 11650,
            "end": 11651
          },
          "context": "del.\n\ni ∈ Rdmodel×dk , W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ Rdmodel",
          "confidence": 1.0,
          "metadata": {
            "type": "mathematical",
            "name": "element_of"
          }
        },
        {
          "symbol": "W",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11665,
            "end": 11666
          },
          "context": "el×dk , W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ Rdmodel×dv\n\nIn this wo",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "V",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 11667,
            "end": 11668
          },
          "context": "×dk , W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ Rdmodel×dv\n\nIn this work",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "∈",
          "type": "mathematical",
          "pattern": "mathematical_symbol",
          "position": {
            "start": 11672,
            "end": 11673
          },
          "context": " W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ Rdmodel×dv\n\nIn this work we e",
          "confidence": 1.0,
          "metadata": {
            "type": "mathematical",
            "name": "element_of"
          }
        },
        {
          "symbol": "∞",
          "type": "mathematical",
          "pattern": "mathematical_symbol",
          "position": {
            "start": 13066,
            "end": 13067
          },
          "context": "n by masking out (setting to −∞) all values in the input\nof t",
          "confidence": 1.0,
          "metadata": {
            "type": "mathematical",
            "name": "infinity"
          }
        },
        {
          "symbol": "FFN",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 13479,
            "end": 13482
          },
          "context": " ReLU activation in between.\n\nFFN(x) = max(0, xW1 + b1)W2 + b2\n",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "FFN",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 13479,
            "end": 13482
          },
          "context": " ReLU activation in between.\n\nFFN(x) = max(0, xW1 + b1)W2 + b2\n",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "√",
          "type": "mathematical",
          "pattern": "mathematical_symbol",
          "position": {
            "start": 14353,
            "end": 14354
          },
          "context": "we multiply those weights by\n\n√\n\n3.5 Positional Encoding\n\nSin",
          "confidence": 1.0,
          "metadata": {
            "type": "mathematical",
            "name": "sqrt"
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15076,
            "end": 15077
          },
          "context": "\nSelf-Attention (restricted)\n\nO(n2 · d)\nO(n · d2)\nO(k · n · d",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15086,
            "end": 15087
          },
          "context": "ntion (restricted)\n\nO(n2 · d)\nO(n · d2)\nO(k · n · d2)\nO(r · n",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15096,
            "end": 15097
          },
          "context": "tricted)\n\nO(n2 · d)\nO(n · d2)\nO(k · n · d2)\nO(r · n · d)\n\nSeq",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15110,
            "end": 15111
          },
          "context": " · d)\nO(n · d2)\nO(k · n · d2)\nO(r · n · d)\n\nSequential Maximu",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15166,
            "end": 15167
          },
          "context": "aximum Path Length\nOperations\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\n",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15171,
            "end": 15172
          },
          "context": "m Path Length\nOperations\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(log",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15176,
            "end": 15177
          },
          "context": "h Length\nOperations\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15181,
            "end": 15182
          },
          "context": "gth\nOperations\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))\nO(n/",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15187,
            "end": 15188
          },
          "context": "erations\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))\nO(n/r)\n\nbo",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15192,
            "end": 15193
          },
          "context": "ons\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))\nO(n/r)\n\nbottoms",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15197,
            "end": 15198
          },
          "context": "(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))\nO(n/r)\n\nbottoms of t",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15208,
            "end": 15209
          },
          "context": "1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))\nO(n/r)\n\nbottoms of the encoder ",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "P",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15510,
            "end": 15511
          },
          "context": "ns of different frequencies:\n\nP E(pos,2i) = sin(pos/100002i/d",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "E",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15512,
            "end": 15513
          },
          "context": " of different frequencies:\n\nP E(pos,2i) = sin(pos/100002i/dmo",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "P",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15548,
            "end": 15549
          },
          "context": "2i) = sin(pos/100002i/dmodel)\nP E(pos,2i+1) = cos(pos/100002i",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "E",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15550,
            "end": 15551
          },
          "context": ") = sin(pos/100002i/dmodel)\nP E(pos,2i+1) = cos(pos/100002i/d",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "π",
          "type": "greek_letter",
          "pattern": "greek_letter",
          "position": {
            "start": 15768,
            "end": 15769
          },
          "context": "a geometric progression from 2π to 10000 · 2π. We\nchose this ",
          "confidence": 1.0,
          "metadata": {
            "type": "greek_letter",
            "name": "pi"
          }
        },
        {
          "symbol": "π",
          "type": "greek_letter",
          "pattern": "greek_letter",
          "position": {
            "start": 15782,
            "end": 15783
          },
          "context": "ogression from 2π to 10000 · 2π. We\nchose this function becau",
          "confidence": 1.0,
          "metadata": {
            "type": "greek_letter",
            "name": "pi"
          }
        },
        {
          "symbol": "P",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15935,
            "end": 15936
          },
          "context": " since for any ﬁxed offset k, P Epos+k can be represented as ",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "P",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 15987,
            "end": 15988
          },
          "context": "ented as a linear function of\nP Epos.\n\nWe also experimented w",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "E",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 16155,
            "end": 16156
          },
          "context": "cal results (see Table 3 row (E)). We chose the sinusoidal ve",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "∈",
          "type": "mathematical",
          "pattern": "mathematical_symbol",
          "position": {
            "start": 16601,
            "end": 16602
          },
          "context": "th (z1, ..., zn), with xi, zi ∈ Rd, such as a hidden\nlayer in",
          "confidence": 1.0,
          "metadata": {
            "type": "mathematical",
            "name": "element_of"
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 17713,
            "end": 17714
          },
          "context": "as a recurrent layer requires O(n) sequential operations. In ",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 18370,
            "end": 18371
          },
          "context": "se the maximum\npath length to O(n/r). We plan to investigate ",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "A",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 18440,
            "end": 18441
          },
          "context": "oach further in future work.\n\nA single convolutional layer wi",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 18580,
            "end": 18581
          },
          "context": " Doing so requires a stack of O(n/k) convolutional layers in ",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 18646,
            "end": 18647
          },
          "context": "ase of contiguous kernels,\nor O(logk(n)) in the case of dilat",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "O",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 18953,
            "end": 18954
          },
          "context": "e complexity\nconsiderably, to O(k · n · d + n · d2). Even wit",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "WMT",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 19653,
            "end": 19656
          },
          "context": "g\n\nWe trained on the standard WMT 2014 English-German dataset c",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "WMT",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 19653,
            "end": 19656
          },
          "context": "g\n\nWe trained on the standard WMT 2014 English-German dataset c",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "WMT",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 19906,
            "end": 19909
          },
          "context": " used the signiﬁcantly larger WMT\n2014 English-French dataset c",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "WMT",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 19906,
            "end": 19909
          },
          "context": " used the signiﬁcantly larger WMT\n2014 English-French dataset c",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "NVIDIA",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 20289,
            "end": 20295
          },
          "context": " models on one machine with 8 NVIDIA P100 GPUs. For our base model",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "β",
          "type": "greek_letter",
          "pattern": "greek_letter",
          "position": {
            "start": 20697,
            "end": 20698
          },
          "context": " the Adam optimizer [17] with β1 = 0.9, β2 = 0.98 and (cid:15",
          "confidence": 1.0,
          "metadata": {
            "type": "greek_letter",
            "name": "beta"
          }
        },
        {
          "symbol": "β",
          "type": "greek_letter",
          "pattern": "greek_letter",
          "position": {
            "start": 20707,
            "end": 20708
          },
          "context": "optimizer [17] with β1 = 0.9, β2 = 0.98 and (cid:15) = 10−9. ",
          "confidence": 1.0,
          "metadata": {
            "type": "greek_letter",
            "name": "beta"
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 21552,
            "end": 21556
          },
          "context": "e Transformer achieves better BLEU scores than previous state-of",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 21552,
            "end": 21556
          },
          "context": "e Transformer achieves better BLEU scores than previous state-of",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "GNMT",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 21748,
            "end": 21752
          },
          "context": "t [15]\nDeep-Att + PosUnk [32]\nGNMT + RL [31]\nConvS2S [8]\nMoE [26",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "GNMT",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 21748,
            "end": 21752
          },
          "context": "t [15]\nDeep-Att + PosUnk [32]\nGNMT + RL [31]\nConvS2S [8]\nMoE [26",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "RL",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 21755,
            "end": 21757
          },
          "context": "Deep-Att + PosUnk [32]\nGNMT + RL [31]\nConvS2S [8]\nMoE [26]\nDee",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "RL",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 21755,
            "end": 21757
          },
          "context": "Deep-Att + PosUnk [32]\nGNMT + RL [31]\nConvS2S [8]\nMoE [26]\nDee",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "GNMT",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 21816,
            "end": 21820
          },
          "context": "ep-Att + PosUnk Ensemble [32]\nGNMT + RL Ensemble [31]\nConvS2S En",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "GNMT",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 21816,
            "end": 21820
          },
          "context": "ep-Att + PosUnk Ensemble [32]\nGNMT + RL Ensemble [31]\nConvS2S En",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "RL",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 21823,
            "end": 21825
          },
          "context": "+ PosUnk Ensemble [32]\nGNMT + RL Ensemble [31]\nConvS2S Ensembl",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "RL",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 21823,
            "end": 21825
          },
          "context": "+ PosUnk Ensemble [32]\nGNMT + RL Ensemble [31]\nConvS2S Ensembl",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 21905,
            "end": 21909
          },
          "context": "ase model)\nTransformer (big)\n\nBLEU\n\nTraining Cost (FLOPs)\n\nEN-DE",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 21905,
            "end": 21909
          },
          "context": "ase model)\nTransformer (big)\n\nBLEU\n\nTraining Cost (FLOPs)\n\nEN-DE",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "EN",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 21934,
            "end": 21936
          },
          "context": "\nBLEU\n\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "EN",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 21934,
            "end": 21936
          },
          "context": "\nBLEU\n\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "DE",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 21937,
            "end": 21939
          },
          "context": "EU\n\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "DE",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 21937,
            "end": 21939
          },
          "context": "EU\n\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "EN",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 21940,
            "end": 21942
          },
          "context": "\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03\n\n2",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "EN",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 21940,
            "end": 21942
          },
          "context": "\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03\n\n2",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "FR",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 21943,
            "end": 21945
          },
          "context": "aining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03\n\n26.3",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "FR",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 21943,
            "end": 21945
          },
          "context": "aining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03\n\n26.3",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "EN",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 22045,
            "end": 22047
          },
          "context": "6\n40.4\n41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "EN",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 22045,
            "end": 22047
          },
          "context": "6\n40.4\n41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "DE",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 22048,
            "end": 22050
          },
          "context": "0.4\n41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "DE",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 22048,
            "end": 22050
          },
          "context": "0.4\n41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "EN",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 22052,
            "end": 22054
          },
          "context": "41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018\n2.0",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "EN",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 22052,
            "end": 22054
          },
          "context": "41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018\n2.0",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "FR",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 22055,
            "end": 22057
          },
          "context": "16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018\n2.0 · ",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "FR",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 22055,
            "end": 22057
          },
          "context": "16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018\n2.0 · ",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 22398,
            "end": 22402
          },
          "context": "re, but improves accuracy and BLEU score.\n\n6 Results\n\n6.1 Machin",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 22398,
            "end": 22402
          },
          "context": "re, but improves accuracy and BLEU score.\n\n6 Results\n\n6.1 Machin",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "WMT",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 22454,
            "end": 22457
          },
          "context": "1 Machine Translation\n\nOn the WMT 2014 English-to-German transl",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "WMT",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 22454,
            "end": 22457
          },
          "context": "1 Machine Translation\n\nOn the WMT 2014 English-to-German transl",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 22643,
            "end": 22647
          },
          "context": "g ensembles) by more than 2.0\nBLEU, establishing a new state-of-",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 22643,
            "end": 22647
          },
          "context": "g ensembles) by more than 2.0\nBLEU, establishing a new state-of-",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 22685,
            "end": 22689
          },
          "context": "ishing a new state-of-the-art BLEU score of 28.4. The conﬁgurati",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 22685,
            "end": 22689
          },
          "context": "ishing a new state-of-the-art BLEU score of 28.4. The conﬁgurati",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "WMT",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 22970,
            "end": 22973
          },
          "context": "e competitive models.\n\nOn the WMT 2014 English-to-French transl",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "WMT",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 22970,
            "end": 22973
          },
          "context": "e competitive models.\n\nOn the WMT 2014 English-to-French transl",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 23040,
            "end": 23044
          },
          "context": "ask, our big model achieves a BLEU score of 41.0,\noutperforming ",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 23040,
            "end": 23044
          },
          "context": "ask, our big model achieves a BLEU score of 41.0,\noutperforming ",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "α",
          "type": "greek_letter",
          "pattern": "greek_letter",
          "position": {
            "start": 23553,
            "end": 23554
          },
          "context": " size of 4 and length penalty α = 0.6 [31]. These hyperparame",
          "confidence": 1.0,
          "metadata": {
            "type": "greek_letter",
            "name": "alpha"
          }
        },
        {
          "symbol": "GPU",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 24110,
            "end": 24113
          },
          "context": "oating-point capacity of each GPU 5.\n\n6.2 Model Variations\n\nTo ",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "GPU",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 24110,
            "end": 24113
          },
          "context": "oating-point capacity of each GPU 5.\n\n6.2 Model Variations\n\nTo ",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "A",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 24504,
            "end": 24505
          },
          "context": "in Table 3.\n\nIn Table 3 rows (A), we vary the number of atten",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 24700,
            "end": 24704
          },
          "context": " single-head\nattention is 0.9 BLEU worse than the best setting, ",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 24700,
            "end": 24704
          },
          "context": " single-head\nattention is 0.9 BLEU worse than the best setting, ",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "TFLOPS",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 24820,
            "end": 24826
          },
          "context": "lues of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, r",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "N",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 25199,
            "end": 25200
          },
          "context": "ed to\nper-word perplexities.\n\nN dmodel\n\ndff\n\nbase\n\n6\n\n512\n\n20",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "A",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 25459,
            "end": 25460
          },
          "context": "ids\n\n6\n\n1024\n\n4096\n\n16\n\n0.3\n\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "B",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 25464,
            "end": 25465
          },
          "context": "6\n\n1024\n\n4096\n\n16\n\n0.3\n\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrai",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "C",
          "type": "stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 25469,
            "end": 25470
          },
          "context": "24\n\n4096\n\n16\n\n0.3\n\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrain\nste",
          "confidence": 1.0,
          "metadata": {
            "type": "stock_ticker",
            "verified": true
          }
        },
        {
          "symbol": "D",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 25474,
            "end": 25475
          },
          "context": "096\n\n16\n\n0.3\n\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrain\nsteps\n(d",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "E",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 25479,
            "end": 25480
          },
          "context": "16\n\n0.3\n\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrain\nsteps\n(dev)\n1",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "PPL",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 25487,
            "end": 25490
          },
          "context": "\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrain\nsteps\n(dev)\n100K 4.92\n5",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "PPL",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 25487,
            "end": 25490
          },
          "context": "\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrain\nsteps\n(dev)\n100K 4.92\n5",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 25620,
            "end": 25624
          },
          "context": ".95\n4.67\n5.47\n4.92\n300K 4.33\n\nBLEU params\n×106\n(dev)\n25.8\n65\n24.",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "BLEU",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 25620,
            "end": 25624
          },
          "context": ".95\n4.67\n5.47\n4.92\n300K 4.33\n\nBLEU params\n×106\n(dev)\n25.8\n65\n24.",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "B",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 25798,
            "end": 25799
          },
          "context": "\n53\n90\n\n213\n\nIn Table 3 rows (B), we observe that reducing th",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "C",
          "type": "stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 26047,
            "end": 26048
          },
          "context": ". We further observe in rows (C) and (D) that, as expected,\nb",
          "confidence": 1.0,
          "metadata": {
            "type": "stock_ticker",
            "verified": true
          }
        },
        {
          "symbol": "D",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 26055,
            "end": 26056
          },
          "context": "ther observe in rows (C) and (D) that, as expected,\nbigger mo",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "E",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 26164,
            "end": 26165
          },
          "context": "avoiding over-ﬁtting. In row (E) we replace our\nsinusoidal po",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "WMT",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 26697,
            "end": 26700
          },
          "context": "convolutional layers. On both WMT 2014 English-to-German and WM",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "WMT",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 26697,
            "end": 26700
          },
          "context": "convolutional layers. On both WMT 2014 English-to-German and WM",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "WMT",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 26728,
            "end": 26731
          },
          "context": "MT 2014 English-to-German and WMT 2014\nEnglish-to-French transl",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "WMT",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 26728,
            "end": 26731
          },
          "context": "MT 2014 English-to-German and WMT 2014\nEnglish-to-French transl",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "E",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 27608,
            "end": 27609
          },
          "context": "amie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. ",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "V",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 27893,
            "end": 27894
          },
          "context": "e, Minh-Thang Luong, and Quoc V. Le. Massive exploration of n",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "N",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 28745,
            "end": 28746
          },
          "context": "ngier, Denis Yarats, and Yann N. Dauphin. Convolu-\n\ntional se",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "IEEE",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 29088,
            "end": 29092
          },
          "context": "nition. In Proceedings of the IEEE Conference on Computer Vision",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "IEEE",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 29088,
            "end": 29092
          },
          "context": "nition. In Proceedings of the IEEE Conference on Computer Vision",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "ICLR",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 29744,
            "end": 29748
          },
          "context": "\non Learning Representations (ICLR), 2016.\n\n[15] Nal Kalchbrenne",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "ICLR",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 29744,
            "end": 29748
          },
          "context": "\non Learning Representations (ICLR), 2016.\n\n[15] Nal Kalchbrenne",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "M",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 30011,
            "end": 30012
          },
          "context": "n, Luong Hoang, and Alexander M. Rush. Structured attention n",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "A",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 30157,
            "end": 30158
          },
          "context": "ik Kingma and Jimmy Ba. Adam: A method for stochastic optimiz",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "ICLR",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 30198,
            "end": 30202
          },
          "context": "r stochastic optimization. In ICLR, 2015.\n\n[18] Oleksii Kuchaiev",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "ICLR",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 30198,
            "end": 30202
          },
          "context": "r stochastic optimization. In ICLR, 2015.\n\n[18] Oleksii Kuchaiev",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "LSTM",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 30278,
            "end": 30282
          },
          "context": "urg. Factorization tricks for LSTM networks. arXiv preprint\n\narX",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "LSTM",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 30278,
            "end": 30282
          },
          "context": "urg. Factorization tricks for LSTM networks. arXiv preprint\n\narX",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "A",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 30443,
            "end": 30444
          },
          "context": "owen\nZhou, and Yoshua Bengio. A structured self-attentive sen",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "NIPS",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 30656,
            "end": 30660
          },
          "context": "ormation Processing Systems, (NIPS), 2016.\n\n10\n\n\f[21] Minh-Thang",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "NIPS",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 30656,
            "end": 30660
          },
          "context": "ormation Processing Systems, (NIPS), 2016.\n\n10\n\n\f[21] Minh-Thang",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "D",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 30725,
            "end": 30726
          },
          "context": "g, Hieu Pham, and Christopher D Manning. Effective approaches",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "A",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 30917,
            "end": 30918
          },
          "context": "jan Das, and Jakob Uszkoreit. A decomposable attention\n\nmodel",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "A",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 31065,
            "end": 31066
          },
          "context": "ng Xiong, and Richard Socher. A deep reinforced model for abs",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "E",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 31708,
            "end": 31709
          },
          "context": "] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "C",
          "type": "stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 32009,
            "end": 32010
          },
          "context": "nd-to-end memory\nnetworks. In C. Cortes, N. D. Lawrence, D. D",
          "confidence": 1.0,
          "metadata": {
            "type": "stock_ticker",
            "verified": true
          }
        },
        {
          "symbol": "N",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 32020,
            "end": 32021
          },
          "context": "emory\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. S",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "D",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 32023,
            "end": 32024
          },
          "context": "ry\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugi",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "D",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 32036,
            "end": 32037
          },
          "context": "In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. ",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "D",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 32039,
            "end": 32040
          },
          "context": "C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Gar",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "M",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 32047,
            "end": 32048
          },
          "context": "s, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, ed",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "R",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 32064,
            "end": 32065
          },
          "context": ", D. D. Lee, M. Sugiyama, and R. Garnett, editors,\nAdvances i",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "VV",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 32233,
            "end": 32235
          },
          "context": "ever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence lear",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "VV",
          "type": "potential_crypto_symbol",
          "pattern": "crypto_symbol",
          "position": {
            "start": 32233,
            "end": 32235
          },
          "context": "ever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence lear",
          "confidence": 0.6,
          "metadata": {
            "needs_validation": true
          }
        },
        {
          "symbol": "V",
          "type": "potential_stock_ticker",
          "pattern": "stock_ticker",
          "position": {
            "start": 32604,
            "end": 32605
          },
          "context": " Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgan",
          "confidence": 0.7,
          "metadata": {
            "needs_validation": true
          }
        }
      ],
      "statistics": {
        "total_symbols": 195,
        "unique_symbols": 43,
        "type_counts": {
          "stock_ticker": 130,
          "crypto_symbol": 49,
          "greek_letter": 5,
          "mathematical_symbol": 11
        },
        "avg_confidence": 0.704102564102564,
        "most_common_symbols": [
          [
            "BLEU",
            22
          ],
          [
            "O",
            19
          ],
          [
            "WMT",
            16
          ],
          [
            "V",
            9
          ],
          [
            "EN",
            8
          ],
          [
            "E",
            7
          ],
          [
            "A",
            7
          ],
          [
            "N",
            6
          ],
          [
            "W",
            6
          ],
          [
            "D",
            6
          ]
        ],
        "symbol_density": 0.195
      },
      "preservation_map": {
        "__SYMBOL_0__": "N",
        "__SYMBOL_1__": "BLEU",
        "__SYMBOL_2__": "BLEU",
        "__SYMBOL_3__": "WMT",
        "__SYMBOL_4__": "WMT",
        "__SYMBOL_5__": "BLEU",
        "__SYMBOL_6__": "BLEU",
        "__SYMBOL_7__": "WMT",
        "__SYMBOL_8__": "WMT",
        "__SYMBOL_9__": "BLEU",
        "__SYMBOL_10__": "BLEU",
        "__SYMBOL_11__": "NIPS",
        "__SYMBOL_12__": "NIPS",
        "__SYMBOL_13__": "CA",
        "__SYMBOL_14__": "CA",
        "__SYMBOL_15__": "USA",
        "__SYMBOL_16__": "USA",
        "__SYMBOL_17__": "GPU",
        "__SYMBOL_18__": "GPU",
        "__SYMBOL_19__": "N",
        "__SYMBOL_20__": "N",
        "__SYMBOL_21__": "√",
        "__SYMBOL_22__": "Q",
        "__SYMBOL_23__": "K",
        "__SYMBOL_24__": "V",
        "__SYMBOL_25__": "Q",
        "__SYMBOL_26__": "K",
        "__SYMBOL_27__": "V",
        "__SYMBOL_28__": "QK",
        "__SYMBOL_29__": "QK",
        "__SYMBOL_30__": "T",
        "__SYMBOL_31__": "√",
        "__SYMBOL_32__": "V",
        "__SYMBOL_33__": "√",
        "__SYMBOL_34__": "√",
        "__SYMBOL_35__": "Q",
        "__SYMBOL_36__": "K",
        "__SYMBOL_37__": "V",
        "__SYMBOL_38__": "W",
        "__SYMBOL_39__": "O",
        "__SYMBOL_40__": "QW",
        "__SYMBOL_41__": "QW",
        "__SYMBOL_42__": "Q",
        "__SYMBOL_43__": "KW",
        "__SYMBOL_44__": "KW",
        "__SYMBOL_45__": "K",
        "__SYMBOL_46__": "V",
        "__SYMBOL_47__": "W",
        "__SYMBOL_48__": "V",
        "__SYMBOL_49__": "W",
        "__SYMBOL_50__": "Q",
        "__SYMBOL_51__": "W",
        "__SYMBOL_52__": "O",
        "__SYMBOL_53__": "∈",
        "__SYMBOL_54__": "∈",
        "__SYMBOL_55__": "W",
        "__SYMBOL_56__": "K",
        "__SYMBOL_57__": "∈",
        "__SYMBOL_58__": "W",
        "__SYMBOL_59__": "V",
        "__SYMBOL_60__": "∈",
        "__SYMBOL_61__": "∞",
        "__SYMBOL_62__": "FFN",
        "__SYMBOL_63__": "FFN",
        "__SYMBOL_64__": "√",
        "__SYMBOL_65__": "O",
        "__SYMBOL_66__": "O",
        "__SYMBOL_67__": "O",
        "__SYMBOL_68__": "O",
        "__SYMBOL_69__": "O",
        "__SYMBOL_70__": "O",
        "__SYMBOL_71__": "O",
        "__SYMBOL_72__": "O",
        "__SYMBOL_73__": "O",
        "__SYMBOL_74__": "O",
        "__SYMBOL_75__": "O",
        "__SYMBOL_76__": "O",
        "__SYMBOL_77__": "P",
        "__SYMBOL_78__": "E",
        "__SYMBOL_79__": "P",
        "__SYMBOL_80__": "E",
        "__SYMBOL_81__": "π",
        "__SYMBOL_82__": "π",
        "__SYMBOL_83__": "P",
        "__SYMBOL_84__": "P",
        "__SYMBOL_85__": "E",
        "__SYMBOL_86__": "∈",
        "__SYMBOL_87__": "O",
        "__SYMBOL_88__": "O",
        "__SYMBOL_89__": "A",
        "__SYMBOL_90__": "O",
        "__SYMBOL_91__": "O",
        "__SYMBOL_92__": "O",
        "__SYMBOL_93__": "WMT",
        "__SYMBOL_94__": "WMT",
        "__SYMBOL_95__": "WMT",
        "__SYMBOL_96__": "WMT",
        "__SYMBOL_97__": "NVIDIA",
        "__SYMBOL_98__": "β",
        "__SYMBOL_99__": "β",
        "__SYMBOL_100__": "BLEU",
        "__SYMBOL_101__": "BLEU",
        "__SYMBOL_102__": "GNMT",
        "__SYMBOL_103__": "GNMT",
        "__SYMBOL_104__": "RL",
        "__SYMBOL_105__": "RL",
        "__SYMBOL_106__": "GNMT",
        "__SYMBOL_107__": "GNMT",
        "__SYMBOL_108__": "RL",
        "__SYMBOL_109__": "RL",
        "__SYMBOL_110__": "BLEU",
        "__SYMBOL_111__": "BLEU",
        "__SYMBOL_112__": "EN",
        "__SYMBOL_113__": "EN",
        "__SYMBOL_114__": "DE",
        "__SYMBOL_115__": "DE",
        "__SYMBOL_116__": "EN",
        "__SYMBOL_117__": "EN",
        "__SYMBOL_118__": "FR",
        "__SYMBOL_119__": "FR",
        "__SYMBOL_120__": "EN",
        "__SYMBOL_121__": "EN",
        "__SYMBOL_122__": "DE",
        "__SYMBOL_123__": "DE",
        "__SYMBOL_124__": "EN",
        "__SYMBOL_125__": "EN",
        "__SYMBOL_126__": "FR",
        "__SYMBOL_127__": "FR",
        "__SYMBOL_128__": "BLEU",
        "__SYMBOL_129__": "BLEU",
        "__SYMBOL_130__": "WMT",
        "__SYMBOL_131__": "WMT",
        "__SYMBOL_132__": "BLEU",
        "__SYMBOL_133__": "BLEU",
        "__SYMBOL_134__": "BLEU",
        "__SYMBOL_135__": "BLEU",
        "__SYMBOL_136__": "WMT",
        "__SYMBOL_137__": "WMT",
        "__SYMBOL_138__": "BLEU",
        "__SYMBOL_139__": "BLEU",
        "__SYMBOL_140__": "α",
        "__SYMBOL_141__": "GPU",
        "__SYMBOL_142__": "GPU",
        "__SYMBOL_143__": "A",
        "__SYMBOL_144__": "BLEU",
        "__SYMBOL_145__": "BLEU",
        "__SYMBOL_146__": "TFLOPS",
        "__SYMBOL_147__": "N",
        "__SYMBOL_148__": "A",
        "__SYMBOL_149__": "B",
        "__SYMBOL_150__": "C",
        "__SYMBOL_151__": "D",
        "__SYMBOL_152__": "E",
        "__SYMBOL_153__": "PPL",
        "__SYMBOL_154__": "PPL",
        "__SYMBOL_155__": "BLEU",
        "__SYMBOL_156__": "BLEU",
        "__SYMBOL_157__": "B",
        "__SYMBOL_158__": "C",
        "__SYMBOL_159__": "D",
        "__SYMBOL_160__": "E",
        "__SYMBOL_161__": "WMT",
        "__SYMBOL_162__": "WMT",
        "__SYMBOL_163__": "WMT",
        "__SYMBOL_164__": "WMT",
        "__SYMBOL_165__": "E",
        "__SYMBOL_166__": "V",
        "__SYMBOL_167__": "N",
        "__SYMBOL_168__": "IEEE",
        "__SYMBOL_169__": "IEEE",
        "__SYMBOL_170__": "ICLR",
        "__SYMBOL_171__": "ICLR",
        "__SYMBOL_172__": "M",
        "__SYMBOL_173__": "A",
        "__SYMBOL_174__": "ICLR",
        "__SYMBOL_175__": "ICLR",
        "__SYMBOL_176__": "LSTM",
        "__SYMBOL_177__": "LSTM",
        "__SYMBOL_178__": "A",
        "__SYMBOL_179__": "NIPS",
        "__SYMBOL_180__": "NIPS",
        "__SYMBOL_181__": "D",
        "__SYMBOL_182__": "A",
        "__SYMBOL_183__": "A",
        "__SYMBOL_184__": "E",
        "__SYMBOL_185__": "C",
        "__SYMBOL_186__": "N",
        "__SYMBOL_187__": "D",
        "__SYMBOL_188__": "D",
        "__SYMBOL_189__": "D",
        "__SYMBOL_190__": "M",
        "__SYMBOL_191__": "R",
        "__SYMBOL_192__": "VV",
        "__SYMBOL_193__": "VV",
        "__SYMBOL_194__": "V"
      }
    },
    "symbol_glossary": {
      "N": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: N",
        "occurrences": 6,
        "contexts": [
          "earch\nllion@google.com\n\nAidan N. Gomez∗ †\nUniversity of Toron",
          "der is composed of a stack of N = 6 identical layers. Each la",
          "s also composed of a stack of N = 6 identical layers. In addi",
          "ed to\nper-word perplexities.\n\nN dmodel\n\ndff\n\nbase\n\n6\n\n512\n\n20",
          "ngier, Denis Yarats, and Yann N. Dauphin. Convolu-\n\ntional se",
          "emory\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. S"
        ],
        "confidence": 0.7
      },
      "BLEU": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: BLEU",
        "occurrences": 22,
        "contexts": [
          "rain. Our model achieves 28.4 BLEU on the WMT 2014 English-\nto-G",
          "ncluding\nensembles, by over 2 BLEU. On the WMT 2014 English-to-F",
          "single-model state-of-the-art BLEU score of 41.0 after\ntraining ",
          "e Transformer achieves better BLEU scores than previous state-of",
          "ase model)\nTransformer (big)\n\nBLEU\n\nTraining Cost (FLOPs)\n\nEN-DE",
          "re, but improves accuracy and BLEU score.\n\n6 Results\n\n6.1 Machin",
          "g ensembles) by more than 2.0\nBLEU, establishing a new state-of-",
          "ishing a new state-of-the-art BLEU score of 28.4. The conﬁgurati",
          "ask, our big model achieves a BLEU score of 41.0,\noutperforming ",
          " single-head\nattention is 0.9 BLEU worse than the best setting, ",
          ".95\n4.67\n5.47\n4.92\n300K 4.33\n\nBLEU params\n×106\n(dev)\n25.8\n65\n24.",
          "rain. Our model achieves 28.4 BLEU on the WMT 2014 English-\nto-G",
          "ncluding\nensembles, by over 2 BLEU. On the WMT 2014 English-to-F",
          "single-model state-of-the-art BLEU score of 41.0 after\ntraining ",
          "e Transformer achieves better BLEU scores than previous state-of",
          "ase model)\nTransformer (big)\n\nBLEU\n\nTraining Cost (FLOPs)\n\nEN-DE",
          "re, but improves accuracy and BLEU score.\n\n6 Results\n\n6.1 Machin",
          "g ensembles) by more than 2.0\nBLEU, establishing a new state-of-",
          "ishing a new state-of-the-art BLEU score of 28.4. The conﬁgurati",
          "ask, our big model achieves a BLEU score of 41.0,\noutperforming ",
          " single-head\nattention is 0.9 BLEU worse than the best setting, ",
          ".95\n4.67\n5.47\n4.92\n300K 4.33\n\nBLEU params\n×106\n(dev)\n25.8\n65\n24."
        ],
        "confidence": 0.7
      },
      "WMT": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: WMT",
        "occurrences": 16,
        "contexts": [
          "del achieves 28.4 BLEU on the WMT 2014 English-\nto-German trans",
          "mbles, by over 2 BLEU. On the WMT 2014 English-to-French transl",
          "g\n\nWe trained on the standard WMT 2014 English-German dataset c",
          " used the signiﬁcantly larger WMT\n2014 English-French dataset c",
          "1 Machine Translation\n\nOn the WMT 2014 English-to-German transl",
          "e competitive models.\n\nOn the WMT 2014 English-to-French transl",
          "convolutional layers. On both WMT 2014 English-to-German and WM",
          "MT 2014 English-to-German and WMT 2014\nEnglish-to-French transl",
          "del achieves 28.4 BLEU on the WMT 2014 English-\nto-German trans",
          "mbles, by over 2 BLEU. On the WMT 2014 English-to-French transl",
          "g\n\nWe trained on the standard WMT 2014 English-German dataset c",
          " used the signiﬁcantly larger WMT\n2014 English-French dataset c",
          "1 Machine Translation\n\nOn the WMT 2014 English-to-German transl",
          "e competitive models.\n\nOn the WMT 2014 English-to-French transl",
          "convolutional layers. On both WMT 2014 English-to-German and WM",
          "MT 2014 English-to-German and WMT 2014\nEnglish-to-French transl"
        ],
        "confidence": 0.7
      },
      "NIPS": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: NIPS",
        "occurrences": 4,
        "contexts": [
          "formation Processing Systems (NIPS 2017), Long Beach, CA, USA.\n\n",
          "ormation Processing Systems, (NIPS), 2016.\n\n10\n\n\f[21] Minh-Thang",
          "formation Processing Systems (NIPS 2017), Long Beach, CA, USA.\n\n",
          "ormation Processing Systems, (NIPS), 2016.\n\n10\n\n\f[21] Minh-Thang"
        ],
        "confidence": 0.7
      },
      "CA": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: CA",
        "occurrences": 2,
        "contexts": [
          "tems (NIPS 2017), Long Beach, CA, USA.\n\n\fRecurrent models typi",
          "tems (NIPS 2017), Long Beach, CA, USA.\n\n\fRecurrent models typi"
        ],
        "confidence": 0.7
      },
      "USA": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: USA",
        "occurrences": 2,
        "contexts": [
          " (NIPS 2017), Long Beach, CA, USA.\n\n\fRecurrent models typically",
          " (NIPS 2017), Long Beach, CA, USA.\n\n\fRecurrent models typically"
        ],
        "confidence": 0.7
      },
      "GPU": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: GPU",
        "occurrences": 4,
        "contexts": [
          "dation of the Extended Neural GPU\n[20], ByteNet [15] and ConvS2",
          "oating-point capacity of each GPU 5.\n\n6.2 Model Variations\n\nTo ",
          "dation of the Extended Neural GPU\n[20], ByteNet [15] and ConvS2",
          "oating-point capacity of each GPU 5.\n\n6.2 Model Variations\n\nTo "
        ],
        "confidence": 0.7
      },
      "Q": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: Q",
        "occurrences": 5,
        "contexts": [
          "packed together\ninto a matrix Q. The keys and values are also",
          "rix of outputs as:\n\nAttention(Q, K, V ) = softmax(\n\nQK T\n√\ndk",
          "k = (cid:80)dk\n\n4\n\n\fMultiHead(Q, K, V ) = Concat(head1, ..., ",
          "O\n\nwhere headi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWh",
          "ions are parameter matrices W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈ R"
        ],
        "confidence": 0.7
      },
      "K": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: K",
        "occurrences": 5,
        "contexts": [
          "packed together into matrices K and V . We compute\nthe matrix",
          " of outputs as:\n\nAttention(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)",
          " (cid:80)dk\n\n4\n\n\fMultiHead(Q, K, V ) = Concat(head1, ..., hea",
          "eadi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the pr",
          "v×dmodel.\n\ni ∈ Rdmodel×dk , W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ Rd"
        ],
        "confidence": 0.7
      },
      "V": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: V",
        "occurrences": 9,
        "contexts": [
          " together into matrices K and V . We compute\nthe matrix of ou",
          " outputs as:\n\nAttention(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n",
          ", V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two most common",
          "id:80)dk\n\n4\n\n\fMultiHead(Q, K, V ) = Concat(head1, ..., headh)",
          "Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the projectio",
          "ntion(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the projections a",
          "×dk , W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ Rdmodel×dv\n\nIn this work",
          "e, Minh-Thang Luong, and Quoc V. Le. Massive exploration of n",
          " Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgan"
        ],
        "confidence": 0.7
      },
      "QK": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: QK",
        "occurrences": 2,
        "contexts": [
          "tention(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two ",
          "tention(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two "
        ],
        "confidence": 0.7
      },
      "T": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: T",
        "occurrences": 1,
        "contexts": [
          "tion(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two mo"
        ],
        "confidence": 0.7
      },
      "W": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: W",
        "occurrences": 6,
        "contexts": [
          " ) = Concat(head1, ..., headh)W O\n\nwhere headi = Attention(QW",
          "tention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the projections",
          "ctions are parameter matrices W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈",
          "re parameter matrices W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈ Rdmodel",
          "hdv×dmodel.\n\ni ∈ Rdmodel×dk , W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ ",
          "el×dk , W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ Rdmodel×dv\n\nIn this wo"
        ],
        "confidence": 0.7
      },
      "O": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: O",
        "occurrences": 19,
        "contexts": [
          " = Concat(head1, ..., headh)W O\n\nwhere headi = Attention(QW Q",
          " parameter matrices W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈ Rdmodel×d",
          "\nSelf-Attention (restricted)\n\nO(n2 · d)\nO(n · d2)\nO(k · n · d",
          "ntion (restricted)\n\nO(n2 · d)\nO(n · d2)\nO(k · n · d2)\nO(r · n",
          "tricted)\n\nO(n2 · d)\nO(n · d2)\nO(k · n · d2)\nO(r · n · d)\n\nSeq",
          " · d)\nO(n · d2)\nO(k · n · d2)\nO(r · n · d)\n\nSequential Maximu",
          "aximum Path Length\nOperations\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\n",
          "m Path Length\nOperations\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(log",
          "h Length\nOperations\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))",
          "gth\nOperations\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))\nO(n/",
          "erations\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))\nO(n/r)\n\nbo",
          "ons\nO(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))\nO(n/r)\n\nbottoms",
          "(1)\nO(n)\nO(1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))\nO(n/r)\n\nbottoms of t",
          "1)\nO(1)\n\nO(1)\nO(n)\nO(logk(n))\nO(n/r)\n\nbottoms of the encoder ",
          "as a recurrent layer requires O(n) sequential operations. In ",
          "se the maximum\npath length to O(n/r). We plan to investigate ",
          " Doing so requires a stack of O(n/k) convolutional layers in ",
          "ase of contiguous kernels,\nor O(logk(n)) in the case of dilat",
          "e complexity\nconsiderably, to O(k · n · d + n · d2). Even wit"
        ],
        "confidence": 0.7
      },
      "QW": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: QW",
        "occurrences": 2,
        "contexts": [
          ")W O\n\nwhere headi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\n",
          ")W O\n\nwhere headi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\n"
        ],
        "confidence": 0.7
      },
      "KW": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: KW",
        "occurrences": 2,
        "contexts": [
          "e headi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the ",
          "e headi = Attention(QW Q\n\ni , KW K\ni\n\n, V W V\n\ni )\n\nWhere the "
        ],
        "confidence": 0.7
      },
      "FFN": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: FFN",
        "occurrences": 2,
        "contexts": [
          " ReLU activation in between.\n\nFFN(x) = max(0, xW1 + b1)W2 + b2\n",
          " ReLU activation in between.\n\nFFN(x) = max(0, xW1 + b1)W2 + b2\n"
        ],
        "confidence": 0.7
      },
      "P": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: P",
        "occurrences": 4,
        "contexts": [
          "ns of different frequencies:\n\nP E(pos,2i) = sin(pos/100002i/d",
          "2i) = sin(pos/100002i/dmodel)\nP E(pos,2i+1) = cos(pos/100002i",
          " since for any ﬁxed offset k, P Epos+k can be represented as ",
          "ented as a linear function of\nP Epos.\n\nWe also experimented w"
        ],
        "confidence": 0.7
      },
      "E": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: E",
        "occurrences": 7,
        "contexts": [
          " of different frequencies:\n\nP E(pos,2i) = sin(pos/100002i/dmo",
          ") = sin(pos/100002i/dmodel)\nP E(pos,2i+1) = cos(pos/100002i/d",
          "cal results (see Table 3 row (E)). We chose the sinusoidal ve",
          "16\n\n0.3\n\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrain\nsteps\n(dev)\n1",
          "avoiding over-ﬁtting. In row (E) we replace our\nsinusoidal po",
          "amie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. ",
          "] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya"
        ],
        "confidence": 0.7
      },
      "A": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: A",
        "occurrences": 7,
        "contexts": [
          "oach further in future work.\n\nA single convolutional layer wi",
          "in Table 3.\n\nIn Table 3 rows (A), we vary the number of atten",
          "ids\n\n6\n\n1024\n\n4096\n\n16\n\n0.3\n\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL",
          "ik Kingma and Jimmy Ba. Adam: A method for stochastic optimiz",
          "owen\nZhou, and Yoshua Bengio. A structured self-attentive sen",
          "jan Das, and Jakob Uszkoreit. A decomposable attention\n\nmodel",
          "ng Xiong, and Richard Socher. A deep reinforced model for abs"
        ],
        "confidence": 0.7
      },
      "GNMT": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: GNMT",
        "occurrences": 4,
        "contexts": [
          "t [15]\nDeep-Att + PosUnk [32]\nGNMT + RL [31]\nConvS2S [8]\nMoE [26",
          "ep-Att + PosUnk Ensemble [32]\nGNMT + RL Ensemble [31]\nConvS2S En",
          "t [15]\nDeep-Att + PosUnk [32]\nGNMT + RL [31]\nConvS2S [8]\nMoE [26",
          "ep-Att + PosUnk Ensemble [32]\nGNMT + RL Ensemble [31]\nConvS2S En"
        ],
        "confidence": 0.7
      },
      "RL": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: RL",
        "occurrences": 4,
        "contexts": [
          "Deep-Att + PosUnk [32]\nGNMT + RL [31]\nConvS2S [8]\nMoE [26]\nDee",
          "+ PosUnk Ensemble [32]\nGNMT + RL Ensemble [31]\nConvS2S Ensembl",
          "Deep-Att + PosUnk [32]\nGNMT + RL [31]\nConvS2S [8]\nMoE [26]\nDee",
          "+ PosUnk Ensemble [32]\nGNMT + RL Ensemble [31]\nConvS2S Ensembl"
        ],
        "confidence": 0.7
      },
      "EN": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: EN",
        "occurrences": 8,
        "contexts": [
          "\nBLEU\n\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26",
          "\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03\n\n2",
          "6\n40.4\n41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1",
          "41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018\n2.0",
          "\nBLEU\n\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26",
          "\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03\n\n2",
          "6\n40.4\n41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1",
          "41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018\n2.0"
        ],
        "confidence": 0.7
      },
      "DE": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: DE",
        "occurrences": 4,
        "contexts": [
          "EU\n\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03",
          "0.4\n41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018",
          "EU\n\nTraining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03",
          "0.4\n41.16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018"
        ],
        "confidence": 0.7
      },
      "FR": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: FR",
        "occurrences": 4,
        "contexts": [
          "aining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03\n\n26.3",
          "16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018\n2.0 · ",
          "aining Cost (FLOPs)\n\nEN-DE EN-FR\n23.75\n\n24.6\n25.16\n26.03\n\n26.3",
          "16\n41.29\n38.1\n41.0\n\nEN-DE\n\nEN-FR\n\n2.3 · 1019\n9.6 · 1018\n2.0 · "
        ],
        "confidence": 0.7
      },
      "B": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: B",
        "occurrences": 2,
        "contexts": [
          "6\n\n1024\n\n4096\n\n16\n\n0.3\n\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrai",
          "\n53\n90\n\n213\n\nIn Table 3 rows (B), we observe that reducing th"
        ],
        "confidence": 0.7
      },
      "C": {
        "type": "stock_ticker",
        "definition": "Stock ticker symbol: C",
        "occurrences": 3,
        "contexts": [
          "24\n\n4096\n\n16\n\n0.3\n\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrain\nste",
          ". We further observe in rows (C) and (D) that, as expected,\nb",
          "nd-to-end memory\nnetworks. In C. Cortes, N. D. Lawrence, D. D"
        ],
        "confidence": 1.0
      },
      "D": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: D",
        "occurrences": 6,
        "contexts": [
          "096\n\n16\n\n0.3\n\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrain\nsteps\n(d",
          "ther observe in rows (C) and (D) that, as expected,\nbigger mo",
          "g, Hieu Pham, and Christopher D Manning. Effective approaches",
          "ry\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugi",
          "In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. ",
          "C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Gar"
        ],
        "confidence": 0.7
      },
      "PPL": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: PPL",
        "occurrences": 2,
        "contexts": [
          "\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrain\nsteps\n(dev)\n100K 4.92\n5",
          "\n(A)\n\n(B)\n\n(C)\n\n(D)\n\n(E)\nbig\n\nPPL\ntrain\nsteps\n(dev)\n100K 4.92\n5"
        ],
        "confidence": 0.7
      },
      "IEEE": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: IEEE",
        "occurrences": 2,
        "contexts": [
          "nition. In Proceedings of the IEEE Conference on Computer Vision",
          "nition. In Proceedings of the IEEE Conference on Computer Vision"
        ],
        "confidence": 0.7
      },
      "ICLR": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: ICLR",
        "occurrences": 4,
        "contexts": [
          "\non Learning Representations (ICLR), 2016.\n\n[15] Nal Kalchbrenne",
          "r stochastic optimization. In ICLR, 2015.\n\n[18] Oleksii Kuchaiev",
          "\non Learning Representations (ICLR), 2016.\n\n[15] Nal Kalchbrenne",
          "r stochastic optimization. In ICLR, 2015.\n\n[18] Oleksii Kuchaiev"
        ],
        "confidence": 0.7
      },
      "M": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: M",
        "occurrences": 2,
        "contexts": [
          "n, Luong Hoang, and Alexander M. Rush. Structured attention n",
          "s, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, ed"
        ],
        "confidence": 0.7
      },
      "LSTM": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: LSTM",
        "occurrences": 2,
        "contexts": [
          "urg. Factorization tricks for LSTM networks. arXiv preprint\n\narX",
          "urg. Factorization tricks for LSTM networks. arXiv preprint\n\narX"
        ],
        "confidence": 0.7
      },
      "R": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: R",
        "occurrences": 1,
        "contexts": [
          ", D. D. Lee, M. Sugiyama, and R. Garnett, editors,\nAdvances i"
        ],
        "confidence": 0.7
      },
      "VV": {
        "type": "potential_stock_ticker",
        "definition": "Symbol: VV",
        "occurrences": 2,
        "contexts": [
          "ever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence lear",
          "ever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence lear"
        ],
        "confidence": 0.7
      },
      "NVIDIA": {
        "type": "potential_crypto_symbol",
        "definition": "Symbol: NVIDIA",
        "occurrences": 1,
        "contexts": [
          " models on one machine with 8 NVIDIA P100 GPUs. For our base model"
        ],
        "confidence": 0.6
      },
      "TFLOPS": {
        "type": "potential_crypto_symbol",
        "definition": "Symbol: TFLOPS",
        "occurrences": 1,
        "contexts": [
          "lues of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, r"
        ],
        "confidence": 0.6
      },
      "π": {
        "type": "greek_letter",
        "definition": "pi",
        "occurrences": 2,
        "contexts": [
          "a geometric progression from 2π to 10000 · 2π. We\nchose this ",
          "ogression from 2π to 10000 · 2π. We\nchose this function becau"
        ],
        "confidence": 1.0
      },
      "β": {
        "type": "greek_letter",
        "definition": "beta",
        "occurrences": 2,
        "contexts": [
          " the Adam optimizer [17] with β1 = 0.9, β2 = 0.98 and (cid:15",
          "optimizer [17] with β1 = 0.9, β2 = 0.98 and (cid:15) = 10−9. "
        ],
        "confidence": 1.0
      },
      "α": {
        "type": "greek_letter",
        "definition": "alpha",
        "occurrences": 1,
        "contexts": [
          " size of 4 and length penalty α = 0.6 [31]. These hyperparame"
        ],
        "confidence": 1.0
      },
      "√": {
        "type": "mathematical",
        "definition": "sqrt",
        "occurrences": 5,
        "contexts": [
          "keys, divide each by\nvalues.\n\n√\n\ndk, and apply a softmax func",
          "on(Q, K, V ) = softmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two most",
          "oftmax(\n\nQK T\n√\ndk\n\n)V\n\n(1)\n\n1√\n\nThe two most commonly used a",
          "we scale the dot products by 1√\ndk\n\n.\n\n3.2.2 Multi-Head Atten",
          "we multiply those weights by\n\n√\n\n3.5 Positional Encoding\n\nSin"
        ],
        "confidence": 1.0
      },
      "∈": {
        "type": "mathematical",
        "definition": "element_of",
        "occurrences": 5,
        "contexts": [
          "arameter matrices W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈ Rdmodel×dk ",
          "W Q\nand W O ∈ Rhdv×dmodel.\n\ni ∈ Rdmodel×dk , W K\n\ni ∈ Rdmodel",
          "del.\n\ni ∈ Rdmodel×dk , W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ Rdmodel",
          " W K\n\ni ∈ Rdmodel×dk , W V\n\ni ∈ Rdmodel×dv\n\nIn this work we e",
          "th (z1, ..., zn), with xi, zi ∈ Rd, such as a hidden\nlayer in"
        ],
        "confidence": 1.0
      },
      "∞": {
        "type": "mathematical",
        "definition": "infinity",
        "occurrences": 1,
        "contexts": [
          "n by masking out (setting to −∞) all values in the input\nof t"
        ],
        "confidence": 1.0
      }
    },
    "academic_analysis": {
      "is_academic_paper": true,
      "confidence": 0.6,
      "score": 9,
      "indicators_found": [
        "abstract",
        "introduction",
        "methods",
        "results",
        "conclusion",
        "references",
        "appendix",
        "citations"
      ],
      "citation_count": 88,
      "recommended_thresholds": {
        "min_tokens": 200,
        "low_quality_tokens": 1000,
        "reference_density_max": 0.15,
        "citation_density_max": 0.1,
        "formula_density_max": 0.2,
        "table_density_max": 0.15,
        "min_sections": 3,
        "bibliography_required": true
      }
    }
  },
  "tables": [
    {
      "table_id": "table_1",
      "page": 9,
      "accuracy": 99.08464415184642,
      "whitespace": 4.166666666666666,
      "order": 1,
      "data": [
        {
          "0": "",
          "1": "trainhdkdvPdrop(cid:15)lsN dmodeldffsteps",
          "2": "PPLBLEU params×106(dev)(dev)"
        },
        {
          "0": "base",
          "1": "65122048864640.10.1",
          "2": "100K 4.9225.865"
        },
        {
          "0": "(A)",
          "1": "15125124128128163232321616",
          "2": "5.2924.95.0025.54.9125.85.0125.4"
        },
        {
          "0": "(B)",
          "1": "1632",
          "2": "5.1625.1585.0125.460"
        },
        {
          "0": "(C)",
          "1": "2482563232102412812810244096",
          "2": "6.1123.7365.1925.3504.8825.5805.7524.5284.6626.01685.1225.4534.7526.290"
        },
        {
          "0": "(D)",
          "1": "0.00.20.00.2",
          "2": "5.7724.64.9525.54.6725.35.4725.7"
        },
        {
          "0": "(E)",
          "1": "positional embedding instead of sinusoids",
          "2": "4.9225.7"
        },
        {
          "0": "big",
          "1": "610244096160.3",
          "2": "26.4300K 4.33213"
        }
      ],
      "shape": [
        8,
        3
      ],
      "extraction_method": "camelot_lattice",
      "worker_id": "pdf_worker_10708_c15c8a3c",
      "temp_dir": "C:\\Users\\USER\\AppData\\Local\\Temp\\pdf_worker_10708_c15c8a3c"
    }
  ],
  "formulas": [
    {
      "formula": "1/4",
      "type": "fractions",
      "position": {
        "start": 23134,
        "end": 23137
      },
      "context": "previously published single models, at less than 1/4 the training cost of the\nprevious state-of-the-ar",
      "confidence": 0.3,
      "metadata": {
        "length": 3,
        "has_greek_letters": false,
        "has_superscript": false,
        "has_subscript": false,
        "has_fractions": true,
        "has_integrals": false,
        "has_summations": false,
        "complexity_score": 0.05,
        "source": "fractions"
      }
    },
    {
      "formula": "Attention Is All You Need\nAshish Vaswani” Noam Shazeee” NIKI Parmar” Jakob Usekoret™\nGoogle Bes Goosle Brain Google Research Google Research\navecuansGgeople.com noentgeogle-com aikiplgoogle-con ueztgoagle.com\nlon Jones” Aidan N. Gomer’! akass Kalser™\nGoogle Research University of Texoma Google Brain\nLiienOgoogle con aidantece.torente,edi  Tukaazkaleertgoogle.com\nMa Potosukhin™\nAbstract\n‘The dominant sequence transduction models are based on complex rcurent or\nconvolutional neural nerworks tha include an encoder and a decoder. The best\npevfonming models alo connect the encoder and decoder though an ateation\n{echanism We proposes new simple network areitecture, the Transformer\nbased solely on atention mechanishs. dispensing with recuence and convolution:\nenliely. Experiments on to machine vansation tsks show these model 19\nbe superiors quality while being moe parallelzable and regu sgnican\nTess tne t tala. Our model achieves 284 BLEU onthe WMT 2014 English\n‘o-German wansation tsk, improving over the existing best esl incling\n‘tebe, by over? BLEU. On the WMT 2014 English-French nsltion ask,\nfourmode establishes ew single-modl sate-ofde-a BLEU sete of 10 afer\n{tuning for 3-5 days on eight GPUs, xsl fraction ofthe taining costs ofthe\ntest model from the Uteratu\n1 Introduction\nRecurrent neural networks, long short-term memory {12} and gated ecutent [7] acura networks\nin particular, have been fray established ss sate ofthe at approaches in sequence modeling and\n‘wansdaction problems such as language modeling and machine wanslton [39,2 5). Namerous\nefforts have tne conned to push he boundaries of recumen language model and cncode-decaer\nSaehiecures (31.21.13\n1 aoa nis Geni. pope pang BN Wh leon ad\n‘fitted ans than aan a ay evgnng ta d",
      "type": "ocr_image",
      "page": 1,
      "confidence": 0.5,
      "source": "ocr_image",
      "metadata": {
        "length": 1756,
        "has_greek_letters": false,
        "has_superscript": false,
        "has_subscript": false,
        "has_fractions": true,
        "has_integrals": false,
        "has_summations": false,
        "complexity_score": 1.0,
        "source": "ocr_image"
      }
    },
    {
      "formula": "Recurrent modes typically factor computation along the symbol positions ofthe input nd outa\nSequences. Aligning the positions to steps in computation tine, they generate a sequence of hidden\n‘ues hy. function ofthe previous hidden staf ad the ip for poiton This inbeently\n‘cnet nature pecodes palliation win tuning examplen which becomes cial st longer\nSequence lengths as memory consis int batching across examples. Revest Work has achieved\nSignificant improvements in computational ficiency dough factoizaton tik [1] and condionl\n‘computation [2], while also amproving model performance in case ofthe ltt. The fundamental\n‘onsaitof sequential computation, however remais.\nAsteaton mechanisms have become a intepa pat of compelling Sequence modeling and ransduc\n‘ion model in various tsk, allowing modeling of dependencies without regard their distance ia\nthe inp or opr sequences (2.16 hall uta ew cae [22] however, sch tenon mechanisms\n‘se ed in conjunction with a ecuent network\nIn this work we propose the Tansforme, a model architecture eschewing recurrence and instead\nselyng entsely cn an ateaion mechansi to dew global dependences between inp and ouput\n‘The Transformer allows for sigecanly more pualelization and can each ew sata he ai\n‘ealtion uality afer being trained for lite steve outs om eight POO GPUs,\n2 Background\n‘The gol of educing sequential computation also forms the foundation ofthe Extended Neural GPU\n(20) ByteNet [15] and ConvS2S [sal of which use coavlutional neural networks as basic ulding\n‘lock computing hidden representations in parle! fr al input and output postions. Tn these models\n‘he number of operations requed to relate sighs roto abitary inp oF ouput sions grONS\ninthe dane between positions, lineal for ConvS2S and logurithncly for ByteNee. Ths takes\n{tmoce dificult learh dependencies between distant postions [11] Inthe transformer tis\nseduce toa constant numberof operations albeit tthe cost of reduced effective resolution doe\n{o averaging atenion weighted positions an effet we counteract wath Muli-Head Attention 35\n‘deseribed in section 32.\nSeleatenton, sometimes called in-atention i an atenton mechanism relating diferent posons\n‘fa single sequence in over wo compute a epresentauon of the sequence. Sel tention hasbeen\n‘sed successfully in aretyof asks including eadig comprehension, abstsctive summarization,\n‘extalenaleat and Tearing tsk-independont sentence fepeesttations (4,22, 23,19)\nEnd-to-end memory networks are based ona recutentstention mechanistn instead of sequence\naligned ecutence and ave been shown wo perform well on simple-anguage question answer abd\ninnguage modeling tasks [3]\n‘othe best of our knowledge, however, the Transformer isthe fist wansdaction model relying\nctiely on el-atention to compute epreseations of inp and ouput without using sequence\nSligned RNNS or convolution Inthe following sections, we wll describe the Tassormet. motte\nSel-ateation and discus is advantages over models such as [14 15] ad [8\n3) Model Architecture\n‘Most competitive neural sequence tansdction models have a encde-decoder structure [5,229\nHere, the encoder maps an input sequence of symbol representations (2...) toa sequence\nof continuous representations 2 = (.--,%,). Given 2 the decoder the generates ah oui\nSequence {y-- im) of symbols one element at atime, Ateac sep the model s autoregressive\n[bY consuming he previously generated symbols as addiinal input When generating the next\n‘The Transformer Follows this overall architecture using stacked self. attention and pointwise, fully\nacted layers or both the encoder and decoder, shown in the lft and sight halves of Figue 1,\n‘spectively.\n|JM_ Encoder and Decoder Stacks\nEncoder: ‘The encader is composed ofa stack of N’ = 6 ientical layers, Each layer has two\nsublayers, The fst ia mulchead sel-atention mechanism. and the second is sinple, positon.\n2",
      "type": "ocr_image",
      "page": 2,
      "confidence": 0.5,
      "source": "ocr_image",
      "metadata": {
        "length": 3871,
        "has_greek_letters": false,
        "has_superscript": false,
        "has_subscript": true,
        "has_fractions": false,
        "has_integrals": false,
        "has_summations": false,
        "complexity_score": 1.0,
        "source": "ocr_image"
      }
    },
    {
      "formula": "eal\n(Ce ss.\n“ Ca) =]\nErevan QP OE\n==) eas\n:",
      "type": "ocr_image",
      "page": 3,
      "confidence": 0.5,
      "source": "ocr_image",
      "metadata": {
        "length": 43,
        "has_greek_letters": false,
        "has_superscript": false,
        "has_subscript": false,
        "has_fractions": false,
        "has_integrals": false,
        "has_summations": false,
        "complexity_score": 0.15000000000000002,
        "source": "ocr_image"
      }
    },
    {
      "formula": "Séalot Do Pads Ateton Muli Head Aeon\n=)\na\nea a a\nCam SEDED\nFut 2: (ef) Sealed Do Product Aton, (igh) Mule Aneton consis of several\n‘von yes ean in oral\nery witha hy, vie cch by Vand apply soa action obtain te wah on the\nwhe\nInprcice, we comput te ation Fintona st of use simultansony pack ose\nIsmace . The keyed alter esa packed wgeler no mater aad V Weconpeas\ntention(@. KV) = ok\nAretion( 9.47) = fina 28 o\n\n‘The two mos conunnly wed tention factions adiveatentin (2 and da prod (ok\nleave) aenton, Dopod tenon ena our gor xc for sealing aor\nSr aLr Adve suennon compte te compat ncn singe foward twa th\nSs sligl hidden ayer Whe the gwo are sma inher eompleriy, dx got anton is\n‘mud ater an ane spacetici n pace, since ean be plement xing gh opis\n\"Wile fr smal lus of te wo mechani pero sina. ive ate ouperfoms\n{oe prodictateon wtousaing for rer vale of [3], Wesuapct tha for ge aes of\ndt he dn grote row lage a gna poring ihe sfx funciona pone wher hat\n‘Siemely all gradient coun heeft we sae the rods ot\n2122 Multead Attention\nInsta of peroming single teton faci with d-dmensiona Lys ves anders,\nte found i neta olineaty poet the quein eye and vals her wi dileen eaed\nThar projections od and denon rerpctely. On cach of exe projected veins of\n(Tien tes and ves then arflom he steno unto Ia all yelling d-mexconal\nShip wala These ae concatte and once gun oct tevin Salva\n‘ipetd in Pue 2\n‘Muti steton allows the mode! tony attend to infomation om diferent sesettion\n‘Stopes ite pono, Wit shops aero head, verging inh hk\n\n“isa wy i dics tls, ee ie compo of an a ned aon\nssi han Oana Pen i roc = Sy gi ha ae dr\n\n4",
      "type": "ocr_image",
      "page": 4,
      "confidence": 0.5,
      "source": "ocr_image",
      "metadata": {
        "length": 1610,
        "has_greek_letters": false,
        "has_superscript": false,
        "has_subscript": false,
        "has_fractions": false,
        "has_integrals": false,
        "has_summations": false,
        "complexity_score": 0.5,
        "source": "ocr_image"
      }
    },
    {
      "formula": "Mulettend(Q. K,V) = Concat( bead, )WV°\nwhore heads = Attention(QW®, KWH, VWY)\n\nWhere the projections are paneer maces 7 € RK Beans YY @ Rau\nand 170 € Ble\nIn this work we employ f= $ parallel atenton layers, heads. For each ofthese we use\n4, == degajh = 64 Dus to the reduced dimension ofeach head, the total computational cos\n{s silat tht ingle-ead tation with fll dimensional\n323 Applications of Attention in our Model\n‘The Transformer uses mul-head tention in thee different ways:\n\n‘+ In “encoderdecoder attention” layers, the queries come from the previous decode ayer\nsnd the mernoy keys and values come from the ouput ofthe encode. This allows every\npositon inthe decoder to atend ove al postions ia the input sequence. This mimes the\n\"ypical encode-decode attention mechanisms in sequence-toseguence models such as\nBL28)\n\n‘+ The encoder contains selF-atenion layers. In se atenton layer alo the Kes, values\nand queries come from the sane place inthis case, te outp ofthe previous layer inthe\n‘encoder. Each poston nthe encoder can attend tal positions inthe previous lye of the\nneeda\n\n«+ Simulay,ste-atention layers in the decoder allow each poston nthe decoder to stend to\nall positions inthe decoder upto and including that postion, We need io prevent leftward\n{information flowin the decoder to preserve the auo-eaessive peopety. We inplement his\nInside of sealed dot product attention by masking out Sting to >) al vals in he ipl\nofthe Sofa which conespond to llegal connections. See Figure 2\n\n133 Positon-wise Feed-Forward Networks\nln addition to ateaion sub-ayers, each ofthe layers in our encoder and decode contains fly\nconnected fod-orwatd network, whichis applied o each poston Separately and dentally. Ths\n‘onsets of wo linea rasformations with ReL.U activation in betwen,\n\nFFN(z) = man(0.2105 +05) +2 2\n‘While the liner transformations at the ste cos diferent postions they use different parameters\nfiom layer to layer. Another way of desing this i a tWo convoltions With kemel size 1\n‘The dimensionality of input atid Outpt is dy = 512, and the innelayer has dimensionality\nayy = 208,\n34 Embeddings and Softmas.\nSimilarly to eter sequence uansduction model, we use Ieamed embeddings 1 conver the inp\n‘okens afd ouput tokens tweets of dimension dy- We also use the usual eared ica wast\n‘maton and softmax function wo convert the decoder ouput to pedictednext-oken probable. 1a\n‘ou model, we share the sae Weight mats between the two embedding layers andthe presoftmak\nTear unsformaton,snulro [24]-In dhe embedding ayers, we mil those Weighs DY da\nAS- Posilonal Encoding\nSince ou model contains no reeureace and no convolution in eder fer he mode! to make use of the\n‘onder of the sequence, we must inj some information about the relative abou postion of he\n{okens ia the sequence. To this end, we add \"positional encodings” tothe input emedngs at the\n\ns",
      "type": "ocr_image",
      "page": 5,
      "confidence": 0.5,
      "source": "ocr_image",
      "metadata": {
        "length": 2871,
        "has_greek_letters": false,
        "has_superscript": false,
        "has_subscript": false,
        "has_fractions": false,
        "has_integrals": false,
        "has_summations": false,
        "complexity_score": 1.0,
        "source": "ocr_image"
      }
    },
    {
      "formula": "‘be L: Maxinum pt legis, prayer complexity and minimum numberof sequential operations\nFordifernt ayer types. ni the sequence length isthe representation dinension is the keel\nsine of conolutios andr the size of the neighborhood in rested selF-ateaon.\n“Toe hpe Complex per Layer Seqeeatal Maximum Pah Length\nOperations\n“SeieAteaion SSCS)\nRecurrent Oin- O(n) O(n)\nConvutonsl Oe na) oun) Ottoneind)\nSelb-Atenton esticed) Orn) ou) Olnr)\n‘toms ofthe encoder and decoder stack. The positional encodings hae the sme dimension das\n‘the embeddings, s thatthe two canbe sumed. There are ny choices of positional encodings\nTeumed nd fixed (8\nIn this wosk, we use sine and cosine functions of diferent frequencies:\nPE on) = sin\\p0s/ 100007\")\nPE gon 204) = €08(008/ 10000)\n‘whore pos isthe postion an is the dimension. That is, cach dimension ofthe positional encoding\noesponds oa sinusoid. The wavelengths form a geometric progression rom 2 10 10000 -27- We\n‘hose tis function because we hypthesied st would allow the model easly ea to atend by\nfelaive positions, since for any fed offiet PE. can be epescied a nea Tnetion of\nPE or\nWe als experimented with using lamed positional embeddings [8] insta and found thatthe 0\nversions produced newly idenical sults (ee Table 3 sow (E). We chose the sinusoidal version\n‘ocaus it may allow dhe model to extaplate to sequence lengths longer than the ones encountered\nsing unig\n4 Why Self-Attention\nln this section we compate various aspects of selattention layers othe recurteat and coavol\n‘oul layers commonly used Tor mapping one variable-length sequence of symbol presentations\n(host) to anaes sequence of equa length (2..u.25). with =, ©. such as a hidden\nlayer in typical sequence ansdaction encoder oe deoder, Moiaing ou use of slf-atetion we\nconsider te desideata,\n(One is the oa computational complexity per ayer. Anoter isthe amount of computation that can\n‘be parlelized s measured by the minimum number of sequential operations que,\n‘The thi isthe path lngth between loag-tange dependencies inthe network. Learins long-cange\ndependencies sky challenge ia many sequence uansduction aks. One key factor aflecting the\nbly to lear such dependencies i the length ofthe pts forward and backwatd signal have 10\n‘eaves in the network The shver these pas betwen any combination of postions in the ip\nan utp sequences the easier itso leat long-range dependencies [1], Hence we so compare\n‘he matimun path length between ay 1 ipl and output postions ia networks composed a he\nslrerent layer pes.\nAs notedin Table | aelfttenton layer connects all positions with constant number of ssquentilly\n‘executed operations, whereas recent layer segues O(n) sequeaual operations. In teams OF\n‘computational complexity. selF-atention layers ae faster tha ecurent ayers when the sequence\nTength ni smaller than the epresentaton dimensionality. which is moet often the cise with\nSenlonce repeseaations used by state-of-the-art models in machine wansations such as weed pcce\n[31] and byte par (25] representations. To improve computational performance foe asks involving\n‘ey long sequences slf-aenton could be ected vo considering oly osighborbood of sizer it\n6",
      "type": "ocr_image",
      "page": 6,
      "confidence": 0.5,
      "source": "ocr_image",
      "metadata": {
        "length": 3176,
        "has_greek_letters": true,
        "has_superscript": false,
        "has_subscript": false,
        "has_fractions": true,
        "has_integrals": false,
        "has_summations": false,
        "complexity_score": 1.0,
        "source": "ocr_image"
      }
    },
    {
      "formula": "the input sequence entered around the respective up positon, This would incest he maximum,\npath length Yo O(n). We plan to ivesigate this approach further in ute Week\nAsngle convolutional layer with kernel width & <n does not connec al pis of input and outa\npostions. Doing so requis astack of O(1/)comvaluonal layers inthe case of contiguous Keel,\n{¢ Ollog() inthe case of dilated convolution [5] ineeasing the length ofthe longest pals\n‘between any two positions in the network. Convolutional layers ae generally more expensive than\nsccurreat layers, by a factor of. Separable convolution [6]. however. decrease the comply\nConsiderably, © O(E nu +). Even with k= n, however, the complexity ofa separable\n“onvotion is equal othe combination of x seleatenion layer anda pointwise fsi-forwatd Lye,\n{he approach we take in our model\nAs side ene self tention could yield moeitrpetable models. We inspect tention dstabutions\nfiom our models and present and discuss examples in the appendix. Not only do individual rtention\n‘ead leary lar o perform diferent asks. many sppea to exhibit behavior veld to he sytactc\nsin semantic stucture ofthe sentences.\n5 Training\n‘This section describes the waining epime for our model\n54 Training Data and Batching\nWe tained oa the standard WMT 2014 English-Geeman dataset consisting of abou 4.5 milion\nsentence pais. Sentences were encoded using byt-par encoding [3], which isa shared source\n{aigtvocaulay of atout 37000 tokens. For English-French, we used the sigan lager WAIT\n2014 English-French dataset consising of 36M sentences and spit wokons ito a 32000 wond-pece\n‘ocablay [31 Sentence pis were batched together by approximate seguonce length, Each waning\nbatch contained ast of sentence puts conning approximately 25000 source tokens and 25000\ntaygt tokens.\n52. Hardware and Schedule\nWe trained our modes on one machine with ® NVIDIA P100 GPUs. For our base modes sing\nte yperparametesdesribed throughout the paper, each traning tp took about 0 seconds. We\ntwine the tase mls for tl of 10,000 step or 12 hours. For ou big models (described oa the\nbottom lie of ble 3), stp tne was 10 seconds, The big models were and for 300,000 steps\nGS days,\n53. Optimizer\nWe used the Adam optimize [17] with 2; = 0.9. 3, = 0.98 and « = 10-9, We vriod the leaning\nsate over the couse a waning, according othe fara\n‘Tis comesponds oincteasing the learning cate linearly forthe fst warmup. steps taining step,\naint doceatng i thereafter proportionally the iver square rot ofthe sep suber We ured\nSA Regularization\nWe employ tee types of regularization ding waning:\nResidual Dropout _ We apply dropout [27] othe ouput ofeach sub-ayer, before itis added othe\nsul-layer input and normalized. In addon, we apply dropout othe sums ofthe embedlings and he\npositional encodings in both he encoder and decoder stacks Fr the base medel, We use 2a Of\nPoop Ol\n\n1",
      "type": "ocr_image",
      "page": 7,
      "confidence": 0.5,
      "source": "ocr_image",
      "metadata": {
        "length": 2873,
        "has_greek_letters": false,
        "has_superscript": false,
        "has_subscript": true,
        "has_fractions": true,
        "has_integrals": false,
        "has_summations": false,
        "complexity_score": 1.0,
        "source": "ocr_image"
      }
    },
    {
      "formula": "‘Table 2: The Transformer achieves beter BLEU sores than pevius state-of the-art models the\nEnglish-o-Gennan and English-French newstest20d test at fraction of the uals cost.\nvoit BLEU “Training Cost FLOPS)\nol ENDE ENR EN-DE ENFR\nSBN TESTS\nDDeep-Att + PosUak (32) 302 10-108\nGNMT-+RL (SI) 246 3992 -28.10 L410\"\nConvs25 (81 25.16 4046 96-10% 15-108\"\n\nMar [26) 26034036 20-10 13:10\"\n~Decp-Att+PosUink Ensemble [2] O80\nGNMT-+RL Ensemble [31] 2630 416 18-10 L110\nConvs28 Ensen] dere 4439771013. 10\n\n“Tiansfomse (base model) 23a S510\n\n‘Transformer bi) 2a a0 23-10%\nLabel Smoothing During waning, we employed label smoothing of value «, = 0.1 (30). This\n‘nuts perplexity. as the model Teams to be more unsure, bu improves accuracy abd BLEU sco\n6 Results\n64 Machine Translation\n(On he WMT 2014 English German translation tsk, the big tansformer model (Tansformer Cig)\n{n Table 2 ouipesTorms the best eevieuly reported models icluing ensembles) BY moee than 20,\nBLEU, extablishing a new state-of-the-art BLEU cove of 28.4. The configuration of ths todel is\nTse inthe hotonline of Table 3. Training ook 3.5 days on 8 P1O0 GPUs. Even our hase model\nsurpasses al previously published models and ensembles aa ation ofthe waning cost of at) of\n‘he competitive model\n(On the WMT 2014 Englih-to French transition isk, ou big model achieves a BLEU score of 41.0,\n‘outperforming al ofthe previously published single modes a less han 1/ the waiing east of the\nfretous state-of the-at model. The Transom (big) model wained for Eaglish-o-French used\nropout ate Pay ~ listed oF 0\nFar the base models, we used a single model obtained by averaging the last S checkpoints, which\nwore writen at 10-minute intervals. Forte big models, we averaged the lst 20 checkpoints. We\n{od beam setch with a beam size of 1 and length penalty a= 06 [SI]. These hyperparametes\n‘were chosen ater experimentation onthe devlopmout se. West the maximus oupa length ding\nInference to input length + 5, but enninat eatly when possible [31\n“Table 2 summarizes our results and compares our uatsation quality and taining costs her model\nrchictures fromthe Hterature. We estinate the number of flatng point operations wed to tain a\n‘del by multiplying the waning tine, te number of GPUs used and an eunate of he sustained\n‘Single-pecsion floating-point capacity ofeach GPU ®\n62 Model Variations\n‘To evaluate the importance of diferent components ofthe Transformer, we varied our base model\n‘in dserent way, measuring the change in performance on English-German waslation on the\nevelopment et newstest2013. We ised bea serch as described inthe previous section, but no\n‘heckpoinaveraping. We present these ress in Table 3\nIn Table cows (A) we vary the number fate heads and he atetion ey and value dimensions,\n[Keeping the amount of computation constnt as described in Section 322 While single-head\naltetion s 09 BLEU worse than the best etn ual also drops ff with too many heads\n\n8",
      "type": "ocr_image",
      "page": 8,
      "confidence": 0.5,
      "source": "ocr_image",
      "metadata": {
        "length": 2931,
        "has_greek_letters": false,
        "has_superscript": false,
        "has_subscript": false,
        "has_fractions": true,
        "has_integrals": false,
        "has_summations": false,
        "complexity_score": 1.0,
        "source": "ocr_image"
      }
    },
    {
      "formula": "Table 3: Vision he Tasfome achieves re etl ta ofthe bse\n‘hve Altice fe Eno Getmn anton deepen se nese Led\nferia prworpee, carding or ye paienoding ad sald compared\nPeto popiice\n: vain | FPL BLEU jams\na\nTsir sz ae\nw toi is mea\nie 2D in Ba\nBout So 34\nie Sie 351\nz eit) 36\ni Pee?\n: is 3 8\n|\" 36 nz Shs 8\nithe i i ie deo ts\ntoot shot 8\n9 ih 32\na S07 ate\nfa i 3\n2 oo 467 253\noo |S 33\nw 492387\niE 48 AB\nIn Tale 3 sows), weohrve ht edicing the ation ky size darts mdel quay. Tis\n‘Sages ta cerning compat fst cay and at 2 ne sphsicaed emp\nitason hn dct gy Bebe We he oan intone Sand Dy aap\nIeper dls rte an dopou isl insvoving vein. now () weeps\n\"Ths poston! ecoing weed ptm eens a sare may nial\n‘Siow be mode\n7) Conclusion\nInti ork, we presen te Tansrme he fist sues ashton model asd ete on\n“oo: aig eeu aes mos anmonnd n eno decode acess 2\nites cto\nFor tat tas, th Tnsorner can be i sigan faster than cites based\nSnccet rcooluina ler On bth WAITS Engle Gean and WA 20\nEgtoenchanslaton ta. we ach a ate of he efor i us\n‘del uperots xe all pel eponedemembien\nWe ae exctedabou he fae of steno ed models apa apply hem tote asks. We\nPiatt eed he Tomtom opts ng pt ap ada hr ans and\n{Dincouu ca eae stenonmecarans en handle ge npas a ous\nShc's ages saan le Mang fenton Iss ser ana sca as fos\nTe cade we ised to win and ethute cut moe is salle at hetpe/ tub con/\nAcknonledgements We eget o Na Kalvene and Stephan Gout fri i\n°",
      "type": "ocr_image",
      "page": 9,
      "confidence": 0.5,
      "source": "ocr_image",
      "metadata": {
        "length": 1412,
        "has_greek_letters": false,
        "has_superscript": false,
        "has_subscript": false,
        "has_fractions": true,
        "has_integrals": false,
        "has_summations": false,
        "complexity_score": 0.30000000000000004,
        "source": "ocr_image"
      }
    },
    {
      "formula": "References\n\n[1} inumy Le Ba, Janie Ryan Kis, and Geoteey E Minton. Layer notmalization. Xi preprint\nrN 1607. 06450, 2016,\n\n[2} Danity Babdanu, Kyunghyun Cho, and Yosbua Beng. Neural machine wanslation by join\nFearing align and wanlte. CofR, abs! T409.0473, 2014\n\n[3} Denny Biz, Anna Goldie. Minh Thang Luong. and Quoc V. Le, Massive exploration of neural\n‘machin anslationachitoctres, CoRR, by! 70303906, 3017\n\n|i) ianpeng Cheng Li Dong nd Mirella Lapa. Loa sheer memoxy- networks for machine\nreaing arXiv preprint arXiv 1601 06788, 2016,\n\n[5] Kyunghyun Cho, Bart van Meutonboer Caglar Glcele,Fethi Boygates, Holgcr Schwenk,\nanu Yoshua Beno, eaming phrase representations using ra encode-decoer Tor staisial\n‘machine wansation, CoRR, abs/id06. 1078, 2014\n\n[6] Francois Chollet. Xception: Deep leaming with depthwise separable convlutons. arXiv\npreprint arXis:161002357, 2016\n\n17) Junyoung Chung, Caslar Gageve, Kyunghyun Cho and Yosbua Bengio. Empiical evaluation\nof gated recent neural etorks on Sequence modeling. CoRR, abW1412 3585, 2014\n\n[8) Jonas Gebring Michael Auli, David Granger, Denis Yaats and Yann N- Dauphin. Convo\nHnal sequence to sequence earning. arXiv preprint arXiv: 1705 0312202, 2017\n\n[9] Alex Graves. Generating sequences with recurrent neural networks. arXty preprint\nfrXi 13080850, 2013,\n\n{10} Kaiming He, Xiangyu Zhang. Shaoging Ren and Jian Sun. Deep residual learning for in\n‘ge recognition. It Proceedings ofthe IEEE Conference on Computer Vision and Patern\nRecognition, pages 770-798, 2016\n\n[ut] Sepp Hocteiter,Yoshua Bengio, Paolo Feascon, and Jurgen Sehmidhuber. Gradient Now in\nrectment net! the difficulty of leaning long-enn dependencies, 2001\n\n[12] Sepp Hochrster and Jurgen Schmidhuber, Long short-term memory. Nevral computation,\n(83:1735-1780, 1997\n\n[13] Rafal Jozefowiez, Oil Vinyas, Mike Schuster, Noam Shazoer. and Youghui Wo, Explocing\nthe linite of language modling.arXi preprint aX: 1602 02410, 2016\n\n[14] Laks Kase and ia Suskever. Neural GPUS lam algrithns. Ia ntemational Conference\n‘on Learning Representations (ICLR), 2016\n\n[US] Nal Kalehbreaes, Lasse Espholt, Kaen imonyan, Aura van den Oot. Alex Graves and Ko\n‘ay Kevukcuoghs, Neural machine translation a iea tie. ark preprint Xi: 1610. 200992,\nbun\n\n{16} Yoou Kim, Cat! Denton, Luong Hoang. and Altander M. Rush Structured astenton netwoks\nIn international Conferonce on Learning Represenations, 2017\n\n[U7] Diederik Kinga and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2018.\n\n[U8) Oletsit Kuchaiv and Bors Ginsburg. Factorization wicks for LSTM network. arXiv preprint\nsrXi: 170810722, 207,\n\n[19] Zhouhan Lin, Minwet Reng, Cicero Nogusea dos Santos, Mo Yu, Bing Xiang, Bowen\n‘Zhou, and Yeshua Bengio. A structed seleatemive sentence enbeing. arXs reprint\nrN 170803130, 2017,\n\n[20] Samy Bengio Lukasz Kaise. Can active memory replace attention? Ia Advances it Newral\nInformation Processing Systems, (NIPS), 2016\n\n0",
      "type": "ocr_image",
      "page": 10,
      "confidence": 0.5,
      "source": "ocr_image",
      "metadata": {
        "length": 2934,
        "has_greek_letters": false,
        "has_superscript": false,
        "has_subscript": false,
        "has_fractions": true,
        "has_integrals": false,
        "has_summations": false,
        "complexity_score": 0.4,
        "source": "ocr_image"
      }
    },
    {
      "formula": "[21] Minh-Thang Luons Hie Pham, and Crstopter D Manning. Este approaches to tention\nBased noual machine tanslaton. aX preprin arXiv 1508 04025, 2013\n\n[22] Ankur Parikh, Oscar Ticksuom, Dipanjan Das, and Jakob Usakoret. A decomposable aeation\n‘odel In Empirical Methods be Natural Language Processing, 2016\n\n[23] Romain Paulus, Calming Xiong. and Richard Soches. deep eafored model fo absactive\nSummatzation” aX preprint arte 708.0609, 2017\n\n[24] Orr Press and Lioe WolE, Using the output embedding 1 improve Language models. arXiv\nreprint arXiv 160805859, 2016.\n\n[25) Rico Sennch, Barty Hadlow and Alexandra Bich. Neural machine ansation of ee words\nwit subword wits arXi preprint ann 50807909, 2018.\n\n[26] Noum Shae, Azala Muhosein, Krzysztof Maziar2, Andy Davis, Quoc Le, Gooey Hinton,\nand eff Dean. Ourageously lage neural networks: The sparselygated mixtue-o-experis\nlayer aX reprint aie 701 06538, 2017\n\n[27] Naish Sivastava, Gooey E Hinton, Alex Krshevsy ya Sutskever, and Ruslan Suakutd\nov. Dropout: a snp way to prevent neural networks fom overiting. Journal of Machine\nLearing Research, 1S) 19291988, 2014\n\n[28) Sainbayar Sukbbautar, arthur slam. Jason Weston, and Rob Fergus. End-o-end memory\ntetworks, In C. Cortes, N-D. Lawrence, B.D, Les, M, Sugiyama, and R. Carnet, editrs,\n‘Advances b Newal Information Processing Systems 38, pages 2140-2448, Cuan Associates\nTne. 2015,\n\n[29] tiya Suskever Oriol Vinyals and Quoe VV Le. Sequence o sequence learing with neural\nnetworks. In Advances in Newel aformation Procesing Sytems, pages 3104-3112, 2014\n\n[30) Chistian Szegedy. Vincent Vanhoucke, Sergey Ioffe Jonathon Shlens and Zbigniew Wojna\nRethinking the inception rhitecture or computer Vision. CoRR, abs/I512. 00867, 2015,\n\n[31] Youghui Wu, Mike Schuster, Zhong Chen, Quoc V Le, Mohammad Novouzi, Wolfgang\nMachete. Maxim Krkun. Yuan Cao Qu Guo, Klaus Machows et Google's neural machine\ntranslation system: eiging the gap between bun and machine tansltion. aX reprint\nrN 1600,08144, 2016,\n\n[32] Jie Zhou, Ying Cao, Xuguang Wang. Peng Li and Wei Xu. Deep securent models with\n‘as-orwatd connections for neural machine warslaton. CoRR, abv 1606 04199, 2016,\n\nu",
      "type": "ocr_image",
      "page": 11,
      "confidence": 0.5,
      "source": "ocr_image",
      "metadata": {
        "length": 2167,
        "has_greek_letters": false,
        "has_superscript": false,
        "has_subscript": false,
        "has_fractions": true,
        "has_integrals": false,
        "has_summations": false,
        "complexity_score": 0.5,
        "source": "ocr_image"
      }
    }
  ]
}