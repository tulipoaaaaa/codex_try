Electronic copy available at: http://ssrn.com/abstract=2034858 
  
THE VOLUME CLOCK : 
INSIGHTS INTO THE HIGH FREQUENCY PARADIGM  
 
 
 
 
David Easley  
Cornell University  
dae3@cornell.edu  
 
 
Marcos M. López de Prado  
Tudor Investment Corp oration  
marcos.lopezdeprado@tudor.com  
 
 
Maureen O’Hara  
Cornell University  
mo19@cornell.edu  
 
 
Journal of Portfolio Management, forthcoming  
 
 
May, 2012  
 
 
 
 
 
 
 
We thank Tudor Investment Corporation for their support, as well as Robert Almgren, Peter 
Carr, David Leinweber, Riccardo Rebonato, Jamie Selway and George Sofianos  for helpful 
comments.  
 
 
 
 
_____________________  
*Scarborough Professor and Donald C. Opatrny Chair Department of Economics, Cornell University.  
**Head of Global Quantitative Research at Tudor Investment Corp.; Research Affiliate at CIFT, Lawrence Berkeley 
National Laboratory . 
***Purcell Professor of Finance, Johnson Graduate School of Management,  Cornell University.  
Electronic copy available at: http://ssrn.com/abstract=2034858 
 THE VOLUME CLOCK:  
INSIGHTS INTO THE HIGH FREQUENCY PARADIGM  
 
ABSTRACT  
 
Over the last two centuries, technological advantages have allowed some traders to be 
faster than others. We argue that, contrary to popular perception, speed is not the defining 
characteristic that sets High Frequency Trading (HFT) apart. HFT is the natur al evolution of a 
new trading paradigm that is characterized by strategic decisions made in a volume -clock  metric . 
Even if the speed advantage disappears, HFT will evolve to continu e exploiting Low Frequency 
Trading ’s (LFT) structural  weaknesses. However, LFT practitioners are not defenseless against 
HFT players, and we offer options that can help them survive and adapt to this new environment . 
 
 
 
 
 
 
 
 
 
 
 
Keywords : High -frequency trading, low -frequency trading, predatory algorithm, volume clock, 
chronological clock . 
 
 
JEL codes : D52, D53, G02.  
Electronic copy available at: http://ssrn.com/abstract=20348581 THE GREAT DIVIDE  
Legend holds that Nathan Mayer Rothschild used racing pigeons to front run his 
competitors and trade on the news o f Napoleon’s defeat at Waterloo  a full day ahead of His 
Majesty’s official messengers (Gray and Aspey [2004]) . Whether this story is true or not, it is 
unquestionable that there have always been faster traders. Leinweber [2009] relates many 
instances in which technological breakthroughs  have been used to most investors’ disadvantage. 
The telegraph gave an enormous edge to some investors over others in the 1850s, perhaps to a 
greater extent than the advantage s enjoyed today by high frequency traders. The same could be 
said of telephone tr aders in the 1875s, radio traders in the 1915s, screen traders in 1986, to cite 
only a few known examples. Since there have always been faster traders  … what is new this time  
around ?  If there is something truly novel  about high frequency trading  (HFT) , it cannot be only 
speed.  
And yet, h igh-frequency traders have been characterized as ‘ cheetah  traders’ , an 
uncomplimentary allusion to their speed and character . The reality is, as usual, more complex. 
Today’s high frequency markets are not the old low frequency markets on steroids. To be sure, 
speed is an important component of high frequency’s success. However, in this article we will 
argue that there is much m ore to it. We will make the case that what lies at the center of HFT  is a 
change in paradigm.  
 
THE NEW TRADING PARADIGM  
The ‘flash crash’ of May 6 , 2010 pushed HFT into the spotlight . To understand what led 
to the emergence of high frequency trading , however, we have to turn the clock back five years 
earlier. HFT  strategies were made possible by legislative changes in the United States 
2 (“Regulation National Market System” of 2005, or “Reg  NMS”) and Europe (“Markets in 
Financial Instruments Directive”  or “MiFID”, in force since November 2007), preceded by 
substantial technological advances in computation and communication.  High -speed trading  had 
been technologically possible for many years, but it was legislative action that made HFT 
profitable . 
Europe ’s MiFID fostered  greater competition among brokers, with the objective of 
improving liquidity, cohesion and depth in financial markets.  MiFID allowed for new, highly 
technological competitors to enter the European markets, thereby introducing competition for 
what had been a relatively quiescent, exchange -dominated market structure.  Similarly, U.S. Reg  
NMS encouraged  competitiveness among exchanges by allowing m arket fragmentation. At this, 
Reg NMS was wildly successful, as the current market structure of 1 3 equity exchanges and 40 
or more alternative venues (dark pools , dealer desks, etc.) attests. Cohesion was  supposedly 
ensured in the U.S . through a mechanism for the consolidation of individual orders processed via 
multiple venues ( the NBBO, or “National Best Bid and Offer”).1 These changes,  combined with 
decimalization of equity markets, result ed in an “arms race” for developing the technology and 
quantitative methods that could extract the last cent of profitability from trading while  serving 
the demands  of market participants.  
The h igh frequency strategies that developed are actually  very diverse. It would be a 
mistake , for example,  to conflate the HFT strategies of cash equities and the HFT strategies of 
futures on equity indices . The reason is  that HFT is not particularly related to macro factors 
(such  as asset class), but it is intimately related to market microstructural factors . While cash 
                                        
1 O’Hara and Ye [2011] present evidence that fragmentation has not degraded market quality in the U.S.  Thus, Reg 
NMS accomplished its goal of creating a single virtual market with many points of entry.  
3 equity markets are fragmented and decimalized, the markets for equity futures  are not , and so the 
first type of HFT strategies have little in common  with the second.  
Many high frequency strategies model the dynamics of the double auction book. This 
allows HFTs to place  numerous independent bets every day on the same instrument or portfolio, 
thus taking advantage of the multiplicative effect postulated by the “Fundamental Law of Active 
Management”, i.e., that a tiny predictive power on a sufficiently large number of independent 
bets yields a h igh Information Ratio and thus a profit  (see Grinol d [1989] ). The goal is to exploit 
the inefficiencies derived from the market’s microstructure, such as rigidities  in price adjustment 
within and across markets , agents’ idiosyncratic behavior , and asymmetric information. As a 
consequence of this higher fre quency, the identification of opportunities, risk control, execution 
and other investment management activities must be automated. Not all algorithmic trading 
occurs in high frequency, but all high frequency requires algorithmic trading.  
It is useful to c ontrast the divergent worlds of the low frequency traders (LFTs) and the 
HFTs. Financial Analysts’ Conferences are one milieu where low frequency traders (LFT) 
converse on subjects as broad and complex  as monetary policy, asset allocation, stock valuations, 
financial statement  analysis , and the like . HFT Conferences are reunions where computer 
scientists meet to discuss TCP/IP connections, machine learning, numeric algorithms to 
determine the position o f an order in a queue, the new est low-latency  co-location architecture, 
game theory, and most important of all, the latest variations  to exchange s’ matching engine s.  
One would conclude, correctly, that the LFTs and the HFTs are seemingly worlds apart.   
The issues surrounding exchange m atching engines are a case in point.  Economists and 
finance professional s often talk about the market ’s auctioning process as a given , but it is 
microstructure theorists  who wade into the minutia of how prices and volumes are actually 
4 formed.  Because the devil is in the details, how exactly the order flow is handled , and thus how 
trades and prices are formed, provides potential profits for those who understand these market 
dynamics  (see Exhibit  1). Over short intervals of time, prices are not the random walks so 
belov ed by the Efficient Market Hypothesis, but can instead be predictable artifacts of the market 
microstructure.   Thus, the paradox of all the billions invested in HFT research  and infrastr ucture  
on a topic that LFTs do not even recognize as an issue . 
[EXHIBIT  1 HERE]  
 
Give n their  dissimilar  background s, it is hardly surprising that HFT professionals would 
operate under a different paradigm than  their LFT peers.  But how did this different background 
translate into a new investment paradigm?  
 
THE MEANING OF TIME  
Time can be understood as a measuring system used to sequence observations. Since the 
dawn of time, humans have based their time measurements in chronolog y: Years, months, days, 
hours, minutes, seconds, and , more  recently, milliseconds, microseconds ... Because we have 
been brought up to think in terms of chronological time, we can hardly visualize a different way 
of scheduling our lives. However, this  is a rather arbitrary time system, arguably due to the key 
role played by the sun in agrarian  societies.  
Machines operate on an internal clock that is not chronological , but event -based: The 
cycle . A machine will complete a cycle at various chrono  rates, depending on the amount of 
information and complexity involved in a particular instruction.  For the reasons mentioned 
earlier , HFT relies on machines, thus measuring time in terms of events  is only natural . Thinking 
in volume -time (or any other ind ex of activity) is challenging for us humans. But for a ‘silicon 
5 trader’, it is the natural way to process information and engage in sequential, strategic trading.  
For example, HF market makers may target to turn their portfolio every fixed number of 
contr acts traded (volume bucket), regardless of the chrono time , in an attempt to keep a certain 
market share . 
The paradigm in this world is “event -based time ”. The simplest example is dividing the 
session in to equal vol ume buckets  (e.g. in 200,000 contract increments, or 20,000 share buckets) . 
In fact, working in volume time presents significant statistical advantages.  First, t his time 
transformation removes most intra -session seasonal effects ; second,  it allows a partial recovery 
of Nor malit y and the IID assumption ; third, sampling in a volume -clock  metric  addresses the 
problem of random and  asynchronous transactions, which is a major concern  when computing 
correlations on high -frequency data .2 
The idea of modeling financial series using a different time clock can be traced back to 
the seminal work of Mandelbrot  and Taylor [1967]  and Clark  [1970 ; 1973] . Ané and Geman 
[2000] is another notable, more recent contribution . Mandelbrot and Taylor open their paper with 
the assertion : 
“Price changes over a fixed number of transactions may have a Gaussian 
distribution. Price changes over a fixed time period may follow a stable Paretian 
distribution, whose variance is infinite. Since the nu mber of transacti ons in any 
time period is random, the above statements are not necessarily in disagreement.  
[…] Basically,  our point is this: the Gaussian ra ndom walk as applied to  
transactions is compatible with a symmetric stable Paretian random walk  as 
applied to fixed  time intervals. ” 
 
In other words, these two authors advocated for  recovering Normality through a 
transaction -based clock , moving away from chronological time . This would treat equally 
                                        
2 A HFT application can be found in Easley et al. [2012a]  
6 transactions of different size.  Clark [1973] suggested a related varian t, arguing  for a volume -
based clock. Mandelbrot [1973] explained the difference between them in the following terms:  
“There is  -as I have said - no dispute between us about the value of the concept of 
subordinated process. Clark's approach is an interesting  and natural modification 
of one described by Mandelbrot and Taylor. The notion is that price change 
would cease to be erratic and would reduce to the familiar Brownian motion if 
only it were followed in an appropriate "local t ime" different from "clock ti me". 
Taylor and I had thought that local time might coincide with transaction time, 
while Clark links it with volume. He also has the merit of having investigated this 
hunch empirically ……. However, it should be kept in mind that if price variation 
is to pr oceed smoothly in local time, then local time itself must flow at random 
and a t a highly variable rate. Consequently, as long as the flow of local time 
remains unpredictable, concrete identification of the applicable local time leaves 
the problems of econo mic prediction unaffected.”  
 
Mandelbrot’s rather negative conclusion regarding the role of “local time” reflected a 
basic reality of the markets in his day: The decisions that participants made were all based on 
chronological time, such as estimating volatilities over a day or returns over a month.  
Consequently, recovering Normality in what he call ed “local time” (i.e., transaction or volu me-
time) d id not seem  helpful , because there is no way to translate the forecast back into 
chronological time . However, as we have argued, HFT operates in event -based time (such as 
transaction or volume), thus removing the need for this translation . HFT will monetize accurate 
forecasts of E -mini S&P500 Futures volatility over the next 50,000 contracts, whatever the 
number of (night -session) hours or (day-session) milliseconds it takes to exchange that volume.  
A HFT market maker has little use for a model that attempts to foreca st volatility over a 
chronological time horizon, because she must keep  her inventory under control in volume time  
(e.g., by turning her inventory over for every 50,000 contracts  exchanged ). Being closer to actual 
Normality and independence of observations (see Exhibit  2) allows for applying standard 
statistical techniques, which means faster calculations , shorter cycles  and thus faster reaction .  
[EXHIBIT  2 HERE]  
7  
The upshot of this new paradigm is clear:  Even if connectivity speed ceased to be a significant 
edge , HFT would and will exist.  
 
MORE THAN SPEED  
Easley et al. [1996]  linked liquidity to informational asymmetry by identifying how 
market mak ers adjust their bid -ask spreads to the probability of informed trading (PIN). Because 
informed trade rs monetize their superior knowledge of a security’s future  price by adversely 
selecting uninformed traders, market makers must update their quoted levels and sizes in real 
time in a manner that reflects their estimate of PIN.  HFT reacts to information leaked by LFT in 
order to anticipate their actions. DMA (Direct Market Access)  allows the deployment of this 
kind of strategic sequential trading logic  to market venues . 
To be clear, strategic sequential trading is not particular to HFT. In October 1990, t he 
British Pound joined the European Exchange Rate Mechanism (ERM). Under that agreement, th e 
Government would have to intervene in order to ensure that the exchange rate between the pound 
and other currencies would not fluctuate beyond a 6% band. Traders knew that, with an inflation 
rate 3 times that of Germany despite high interest rates, in addition to double digit deficits, the 
British Government’s position was extremely vulnerable. Thus, a strategy could be devised to 
take advantage of that Government’ s predictable behavior. On September 16, 1992 (Black 
Wednesday) a group of speculators launched an uncoordinated attack to force the withdrawal of 
the British Pound from the ERM.3 
                                        
3 HM Treasury, “Reflections on the UK’s membership of the ERM” , January 5, 1994. Available at 
http://webarchive.nationalarchives.gov.uk/+/http://www.hm -
treasury.gov.uk/about/information/foi_disclosures/foi_erm4_090205.cfm   
8 What makes HFT such a great example of strategic  sequential trading is its “event -based ” 
interaction with the exchange’s matching engine through DMA . Its decision making process is 
synchronized with the speed at which actions take place , thus acting upon the revelation of new 
information . A good metaphor of strategic sequential trading can be found in poker or  chess. A 
chess player makes moves at different speeds during a game, depending on several factors : 
Superiority over the adversary, stage of the game, amount of material lost, computational power, 
experience with the existin g position, time remaining before the end of the game, etc . It would 
make little sense for a chess player to attempt making moves every minute (even if that were  
possible), but rather moves take place whenever the processing of the new information permits , 
according to the aforementioned factors . With every move, each player reveals information about 
her knowledge of the game, which can be used by an experienced adversary to lead the opponent 
to an uncomfortable situation. Once  the adversary has made a move , the player  has new 
information on the board  to be cycled . Players try to anticipate each other’s moves several steps 
ahead, and force the adversary to make an error . The next move is conditional  upon the 
opponent’s previous moves as well as her own. Ther e are sacrifices, calculated “mistakes” and a 
lot of deception . All of these features are present in HFT.  
Predatory algorithms constitute a very distinct species of informed traders, because of the 
nature of their information and the frequency of their act ions. Such HFT algorithms  exploit a 
microstructural opportunity in a similar way that large speculators exploit a macroeconomic 
inconsistency. Rather than possessing exogenous information yet to be incorporated in the 
market price, they know that their endogenous actions are likely to trigger a microstructure 
mechanism, with foreseeable outcome. Their advent has transformed liquidity provision into a 
tactical game. A few examples discussed in the literature include:  
9  Quote stuffers : They engage in ‘latenc y arbitrage’. The strategy involves 
overwhelm ing an exchange with messages, with the sole intention of slowing down 
competing algorithms, which are forced to parse messages that only the ori ginators 
know  that can be ignored.4 
 Quote danglers : This strategy  sends quotes that force a squeezed trader to chase a 
price against her interests. O’Hara [2011] presents evidence of their disruptive 
activities.  
 Liquidity squeezers : When a distressed large investor is forced to unwind her 
position, they trade in the same  direction, draining as much liquidity as possible. As a 
result, prices overshoot and they make a profit (Carlin, Sousa Lobo and Viswanathan 
[2007]).  
 Pack hunters : Predators hunting independently become aware of each other’s 
activities, and form a pack in order to maximize the chances of triggering a cascading 
effect (Donefer [2010], Fabozzi, Focardi and Jonas [2011] , Jarrow and Protter 
[2011] ). NANEX [2011] shows what appears to be pack hunters forcing a stop loss.  
Although their individual actions are too small to raise the regulator’s suspicion, their 
collective action may be market -manipulative. When that is the case, it is very hard to 
prove their collusion, since they coordinate in a decentralized, spontaneous m anner.  
 
Arnuk and Saluzzi [2009] were among the first to highlight the dangerous trend in order 
cancellation rates. The SEC[2011] admits that “a vast majority” of orders are now cancelled 
(estimates by TABB group put this at 98%)5, and is exploring “ways to fairly allocate the costs 
imposed by high levels of order cancellations, including perhaps requiring a  uniform fee across 
all Exchange markets that is assessed based on the average of order  cancellations to actual 
transactions effected by a market participant ” (p.13).     
Because of the threat posed by predators, high frequency liquidity providers must be 
much more tactical  (see Exhibit  3 for an example) . Sometimes they may suddenly pull all orders, 
liquidate their positions and  stop providing liquidity  altogether . This decision has more to do 
with computer science and game theory than it does with valuation fundamentals. The resulting 
price actions may seem absurd from an economic perspective , but because the actors made their 
                                        
4 NANEX, “Analysis of the ‘Flash Crash’” , June 18, 2010. Available at 
http://www.nanex.net/20100506/FlashCrashAnalysis_CompleteText.html   
5 See “ SEC May Ticket Speeding Traders ,” Wall Street Journal, February 23, 2012.  
10 decisions applying a different rationale  their behavior is perfectly sensible .6 Carlin, Sousa Lobo , 
and Viswanathan [2007] model how predatory trading can lead to episodic liquidity crises and 
contagion.  
[EXHIBIT  3 HERE]  
 
For the HFT trader, t he name of the game is not to move as fast as possible, but rather to 
make the best possible move (before a competitor does) with the information revealed. To 
understand what this implies for market behavior, consider the simple issue of trade size. Easley  
et at. [2012b] report that more than 50% of trades in the S &P500 E-mini futures are now for 1  
contract . Trade frequency quickly drops beyond sizes over 10. However, trades of size 100 are 
up to 17 times more frequent tha n trades of size 99 or 101 in the e -Mini S&P500. The reason is  
that many GUI (Graphical User Interface) traders have buttons for sizes with round numbers. 
HFT algorithms know that if many participants are operating with round numbers in a given 
moment of th e trading session, the market is likely to behave in a particular way. Even though 
trading algorithms are not intelligent in the human sense (at least  not yet), machine learning and 
game theory allows them to identify deep patterns in market activity.  Predictable behavior can 
then be taken advantage of by silicon traders.  
Databases with trillions of observations are now c ommonplace in financial firms. 
Machine learning methods, such as Nearest Neighbor  or Multivariate Embedding algorithms 
search for patterns  within a library of recorded events. This ability to process and learn from 
what is known as “big data” only reinforces the advantages of HFT’s “event -time” paradigm , 
very much like how “Deep Blue” could assign probabilities to Kasparov’s next 20 move s, based 
                                        
6 S.E.C. Chairman Mary Shapiro made this point in her “Testimony Concerning the S evere Market Disruption on 
May 6, 2010”  before the Subcommittee on Capital Markets, Insurance and Government Sponsored Enterprises of 
the United States House of Representatives Committee on Financial Services . May 11, 2010. Available at 
http://sec.gov/news/testimony/2010/ts051110mls.pdf   
11 on hundreds  of thousands of past games  (or more recently, why Watson could outplay his 
Jeopardy opponents ).  
The upshot is that  speed makes HFTs more effective, but slowing them down won’t 
change their basic behavior: Strategic sequential trading  in event time .       
 
LIKE SHEEP AMONG WOLVES?  
A number of studie s have found that HFT is beneficial  in many ways  (see Broogard 
[2012] ; O’Hara and Linton [201 1]; Hasbrouck and Saar [2011] ). Evidence suggests that HFT has 
added liquidity to the markets , narrowed spreads , and enhanced informational efficiency . But 
other studies, like Zhang [2010], find evidence that HFT heightens volatility.  There are also 
concerns that HFT  liquidity providers  are too tactical in nature (they  can vanish when most 
needed). In addition, there are clearly substantial expenses needed for LFT s to develop 
countermeasures  against predatory algorithms . The debate regarding the social benefit of HFT is 
far from closed .  
What does appear clear is that H FT cannot be un -invented, or regulated  away , without 
some sev ere market effects. HFT now  controls the liquidity provision process, and over 70% of 
all U.S. cash equity trades involve a high frequency counterpart (Iati [2009]).  HFT participation 
in futures  is similarly important, with estimates ranging to more than 50% .  While debates rage 
over regulatory control, there is little consensus as to what is desirable, or even feasible.  National 
Tobin taxes are doomed to fail, and an international agreement is unlikely. It is not even clear 
that they would do any good, other than change the rules of the game, to which HFT strategies 
can easily adapt. An alternative that seems closer to the core of the HFT paradigm is a tax on 
FIX messages (as opposed to a tax on transactions). Some exchanges and regulators are 
12 proposing charges on message traffic, b ut this would also affect algorithmic trading by LFTs , a 
form of “collateral damage” that s eems undesirable.  More to the point,  such changes  would not 
completely eliminate all sequential strategic behavior.   The new paradigm that underlies HFT is 
not really about speed, so regulatory efforts to slow “cheetah traders” miss the larger point that 
what is undesirable are particular manipulative strategies and not HFT per se.  
There is no question that the goal of many HFT strategies is to profit from LFT’s  
mistakes.  Exhibit 4 shows how easy this has become. We have taken a sample of E -mini 
S&P500 fut ures trades  between 11/07/2010 and 11/07/2011. We have divided the day in 24 
hours (y -axis), and for every hour, added the volume traded at each second (x -axis), irrespective 
of the minute. For example, E -mini S&P500 futures trades that occur at 20:20:01 G MT and 
20:23:01 GMT are added together.7 This analysis allows us to see the distribution of volume 
within each minute as the day passes, and search for LFTs executing their massive trades on a 
chronological time -space.  The largest concentrations of volume within a minute tend to occur 
during the first few seconds, for almost every hour of the day. This is particularly true at 02:00 -
03:00 GMT (around the open of European equities), 13:00 -14:00 GMT (around the open of U.S. 
equities) and 20:00 -21:00 GMT (aroun d the close of U.S. equities).  This is the result of TWAP 
algorithms and VWAP algorithms that trade on 1 minute slots.  A mildly sophisticated HFT 
algorithm will evaluate the order imbalance at the beginning of every minute, and realize that 
this is a persi stent component, thus front -running VWAPs and TWAPs while they still have to 
execute the largest part of the trade.   
[EXHIBIT 4 HERE]  
 
                                        
7 We are using the GMT convention for time, as G LOBEX  does.  
13 This is just one example of h ow vulnerable the “chronological time” paradigm has made 
LFTs, but t here are dozens of insta nces like this. Easley et al. [2012b] show that about 51.56% of 
E-mini S&P500 futures trades between 11/07/2010 and 11/07/2011  were for one contract.  For 
example, orders of size 10 are 2.9 times more frequent than orders of size 9. Size 50 is 10.86 
times more likely than size 49.  Because ‘GUI traders’ tend to submit round order sizes, ‘silicon 
traders’ can easily detect when there is a disproportionate presence of humans in the market and 
act on that knowledge . These behaviors are a likely cause of the inc reasing number of short -term 
liquidity crises over the past few years . 
But just as markets have evolved, so , too, can LFTs . Part of HFT’s success is due to the 
reluctance of LFT to adopt (or even to recognize) their paradigm . We believe that  LFT players 
have multiple choices  to survive in this new HFT era. These include:  
Choice # 1: Where possible, LFT firms should adopt the HFT “event -based time” 
paradigm . For issues such as portfolio selection, event -based time may not seem particularly  
relevant.  There is an increasing awareness, however, that alpha capture cannot be done in 
isolation from trading – i.e. the implementation of portfolio selection requires trading, and this 
places it firmly in the purview of the HF T world.  The best portf olio selection ability is useless if 
HFT algos can free -ride on your trades and drive up your execution costs.   
 
Choice #2: Develop statistics to monitor HFT activity and take advantage of their 
weaknesses . There is some evidence that “big data” is not nec essarily an advantage in all 
instances.  For example, in other work (see Easley et al. [2012b] ) we found  that “bulk volume 
classification” determines the aggressor side of a trade with greater accuracy than the tick rule 
applied on tick data!  We also show t hat low er-frequency statistics (like VPIN) can detect the 
toxicity in the market  and determine the optimal trading horizon .  Monitoring market conditions 
for high toxicity can be particularly beneficial for LFTs .  In the ‘flash crash ’, the Waddell and 
Reed trader would surely have been well advised to defer trading rather than to sell, as they did, 
in a market experiencing historically high toxicity levels.  
 
Choice #3: Join the herd.  Trade with volume bursts, like at the opening and cl osing of the 
session, when your footprint is harder to be detected.  Transactions cost now largely consist of 
price impact cost, and astute LFTs must use TCA (transaction cost analysis) products that are 
predictive, rather than simply reactive.  Naïve trad ing strategies are simply bait for predatory 
algos.     
 
14 Choice # 4: Use “smart brokers”, specialized in searching for liquidity and avoiding a 
footprint . As we have seen, HFT algos  can easily detect when there is a human in the trading 
room, and take advantage.  Advanced brokers use HFT technology in a different way. Rather than 
attempting to identify patterns for alpha -generation purposes, they avoid actions that may leave 
recogniza ble footprints. For example, TWAP is highly predictable and should be avoided . 
VWAP joins the herd, however in a predictable way. VWAP algos are insensitive to the damage 
done to liquidity providers. A smart VWAP algo would incorporate a feedback mechanism  that 
adjusts the execution horizon in real time, as it recognizes the damage done by prior child orders . 
New algorithms by the more sophisticated brokers use volume patterns , dark executions and the 
like to reduce the footprint of  their trades  (see Easley  et al. (2012c) for an example).  
 
Choice # 5: Trade in exchanges that incorporate technology to monitor order flow toxicity . 
Toxic order flow disrupts the liquidity provision process by adversely selecting market makers.  
An exchange that prevents such disruptions will attract further liquidity, which in turn increases 
the corporate value of its products.  One way to avoid disruptions is to make it harder for 
predators to operate in that exchange.   Exchanges have been changing their trading systems to 
cater to HFTs (and the resulting liquidity  they provide). But exchanges could also modify  their 
matching engines to respond to toxicity changes that can impair liquidity provision to LFTs.  
 
Choice #6: Avoid seasonal effects . Predatory algos exp loit humans’ incli nation for seasonal 
habits, such as  end-of-day hedges, weekly strategy decisions , monthly portfolio duration 
rebalances, calendar rolls, etc. Seasonal effects are easily predictable and are a favorite of HFT 
algos.   Smart LFT trading will avo id these easily exploitable seasonal habits.  
 
CONCLUSIONS  
HFT is here to stay. The current speed advantage will gradually disappear, as it did in 
previous technological revolutions. But HFT’s strategic trading behavior, executed by automated 
systems interacting directly with the exchange’s double auction order book  is more robust . 
Strategic traders have little trouble in adapting to new rules of the game.  “Big data” allows them 
to train their algos before deployment. Advances in machine learning and microstructure theory 
will compensate for the loss of speed advantage.  
Part of HFTs success is LFTs reluctance to adopt the volume -clock paradigm.  However , 
LFTs are not completely defenseless against HFTs. Whenever  a new predator makes its 
appearance in a habitat, there is a shock  period until the hunted species adapt and evol ve. There 
is a natural balance between HFTs and LFTs . Just as in nature the number of predators is limited 
15 by the availa ble prey, the number of HFTs is constrained by the available LFT flows.  Rather than 
seeking “endangered species” status for LFTs (by virtue of legislative action like a Tobin tax or 
speed limit), it seems more efficient and less intrusive to starve some HFTs by making LFTs 
smarter.  Carrier pigeons or dedicated fib er optic cable notwithstanding, the market still operates 
to provide liquidity and price discovery  – only now it does it  very quickly  and strategically . 
 
  
16 Exhibit 1 – Simplified depiction of a M atching Engine’s host  
 
 
 
Prices and volumes are determined by the matching engine. HFTs study its design very carefully, 
in an attempt to uncover a structural weakness in the double auctioning process.  Eurex  has been 
particularly transparent in describing its architecture  and functionality, in an attempt to level the 
playing field  across customers.  
 
  

17 Exhibit 2 – Partial recovery of Normality through a price sampling process  
subordinated to a volume clock  
 
 
 
The red line is the distribution of standardized price changes for the E -mini S&P500 futures 
when we sample every minute. The blue line is the equivalent if we sample every 1/50 of the 
average daily volume. The black dashed line is the standard normal dis tribution. The sample 
goes from January 1st 2008 to October 22nd 2010 . 
 
 
  
00.050.10.150.20.25
-5 -4 -3 -2 -1 0 1 2 3 4 5
Time clock Volume clock Normal Dist (same bins as Time clock)
18 Exhibit 3 – Example of a Tactical Liquidity Provision algorithm  
 
 
 
This algorithm would send an order at the bid (b), wait for a passive fill (Fb=True) and only then 
send an order at the offer ( Counter b ). At all times the probability of a n adverse  change in level is 
monitored (pb). However, if the order at the bid has not been filled yet (Fb=False) by the time 
there is an increase in the probability of adverse level change (pb>t), then the algorithm cancels 
the order (b).  This is a typical sequential trading algorithm that conditions the provision of 
liquidity to a limited number of scenarios. In fact, it becomes a liquidity consumer from time to 
time: If the order got filled (Fb=Tr ue) and the level drops beyond a certain stop loss threshold 
(SL), the algorithm competes for liquidity  (box in red) . 
  
pb:= Probability of bid to be crossed (1 if already crossed)
pa:= Probability of ask to be crossed (1 if already crossed)
Pb:= price filled for Send b
Pa:= price filled for Send a
Zv:= zScore on Volume buckets
t=(0,1):= Threshold on Collapse Probability
v=2:= Threshold on Volume ratio
w=1:= Threshold on Volume Z-Score
SOS=1:= Standard Order Size
SL:= Stop Loss for single Send order
PT:= Profit Target for Send order
Fb=(True,False):= bid was filled
Fa=(True,False):= ask was filled
Qb=(True,False):= bid in queue
Qa=(True,False):= ask in queue
b
Fb=True Fb=False
Position=0 Position>0 Fa=True Fa=False
Reset b Counter b P+SL<=Pa No action Qb=True AND Position>=0 Qb=False AND Position<=0
Passive Neutral b (It would be redundant) pb<=t pb>t pb<=t
Order Size = -Filled b
Limit = Pb + PT Reset b Keep b Cancel b μb/μa>v
Passive at traded price Reset b abs(Zv)<w
Order Size = -(Filled b -Filled Counter b)
Cancel any remaining Send b or Counter b worked Send b
Passive
Order Size = SOS -Current working at that limit
Cancel all b orders at different limit
If Position<0, second passive order for -Position ( Flat b )
a
Fa=True Fa=False
Position=0 Position<0 Fb=True Fb=False
Reset a Counter a P-SL>=Pb No action Qa=True AND Position<=0 Qa=False AND Position>=0
Passive Neutral a (It would be redundant) pa<=t pa>t pa<=t
Order Size = -Filled a
Limit = Pa - PT Reset a Keep a Cancel a μa/μb>v
Passive at traded price Reset a abs(Zv)<w
Order Size = -(Filled a -Filled Counter a)
Cancel any remaining Send a or Counter a worked Send a
Passive
Order Size = -SOS -Current working at that limit
Cancel all a orders at different limit
If Position>0, second passive order for -Position ( Flat a )
19 Exhibit 4 – Percentage of E -Mini S&P500 futures volume traded at each second of every 
minute  
 
 
 
LFT’s decisions are typically made in “chronological time”, leaving footprints that can be 
tracked down easily. The surface above shows a large concentration of volume (over 8%) traded 
in the first second of every minute around the close of U.S. equities.  Because HFTs operate in 
“volume clock”, they can act as soon as the pattern is identified and anticipate the side and sign 
of LFTs’ massive orders for the rest of the hour.  Most academic and practitioner models have 
been devised in  “chronological time” , which means that their implementation  will lead to 
patterns that HFTs can exploit to their advantage.  
 
 
  
0
4
8
12
16
200%1%2%3%4%5%6%7%8%9%
1
4
7
10
13
16
19
22
25
28
31
34
37
40
43
46
49
52
55
58Hour% of that minute's volume
Second8%-9%
7%-8%
6%-7%
5%-6%
4%-5%
3%-4%
2%-3%
1%-2%
0%-1%
20 REFERENCES  
 
Ané, T., and H. Geman.  “Order Flow, Transaction Clock and Normality of Asset Returns.”  
Journal of Finance, 55  (2000 ), pp.  2259 –2284.  
Arnuk, L. and J. Saluzzi. “ Toxic Equity Trading Order Flow and Wall Street .” Themis Trading 
LLC White Paper,  December 17 , 2008 . Available at 
http.//www.themistrading.com/article_files/0000/0348/Toxic_Equity_Trading_on_Wall_
Street_12 -17-08.pdf   
Brogaard, J. “High Frequency Trading and Volatility.” working paper, 2012. Available in SSRN.  
Brunnermeier, M. and L.H. Pedersen  (2005 ). “Predatory Tr ading .” Journal of Finance, Vol. 40, 
No. 4  (August  2005) , pp. 1825 -1863 . 
Carlin, B., M . Sousa Lobo and S. Viswanathan  (2005 ). “Episodic Liquidity Crises . Cooperative 
and Predatory Trading .” Journal of Finance, Vol. 42, No. 5 , October  2005 , pp. 2235 -
2274.  
Clark, P. K.  “A Subordinated Stoc hastic Process Model of Cotton Futures Prices.” unpublished 
Ph.D. dissertation, Harvard University, May 1970 . 
Clark, P. K.  “A Subordinated Stochastic Process Model with Finite Variance for Speculative 
Prices.” Econometrica,  Vol. 41, No. 1 (1973), pp. 135 -155. 
Donefer, B.S. “ Algos Gone Wild . Risk in the World of Automated Trading Strategies .” The 
Journal of Trading, 5 (2010), pp.  31-34. 
Easley, D., N. Kiefer,  M. O’Ha ra, and J. Paperman. “ Liquidity, Information,  and Infrequent ly 
Traded Stocks.” Journal of Finance , Vol.  51 (1996) , pp. 1405 -1436 . 
Easley, D., R. F. E ngle, M. O’Hara and L. Wu.  “Time -Varying Arrival Rates of Informed and 
Uninformed Traders .” Journal of Financial Econometrics, Vol. 6, No. 2 (2008), pp. 171 -
207. 
Easle y, D., M. López de Prado, and M. O’Hara . “The Microstructure of the Flash Crash . Flow 
Toxicity, Liquidity Crashes and the Probability of Informed Trading ”. The Journal of 
Portfolio Management , Vol. 37, No. 2 (2011), pp. 118–28. 
http.//ssrn.com/abstract=1695041   
Easley, D., M. López de Prado, and M. O’Hara. “Flow Toxicity and Liquidity in a High 
Frequency World.”  Review of Financial Studies, Vol. 25, No. 5,  (2012a), pp. 1457 -1493. 
http.//ssrn.com/abstract=1695596  
Easley, D., M. López de Prado and M. O’Hara. “Bulk Volume Classification .” Working paper  
(2012b).  http.//ssrn.com/abstract =1989555   
21 Easley, D., M. López de Prado and M. O’Hara. “Optimal Execution Horizon.”  Working paper  
(2012c).  http://ssrn.com/abstract=2038387   
Fabo zzi, F., S. Focardi and C. Jonas. “ High -Frequency Trading . Methodologies and market 
impact .” Review of Futures Markets, 19  (2011) , pp. 7-38 
Gray , V. and M . Aspey . “Roths child, Nathan Mayer (1777 –1836).”  Oxford Dictionary of 
National Biography, Ox ford University Press, (September 2004).  
Grinold, R.  “The Fundamental  Law of Active Management .” Journal of Portfolio Management, 
Vol. 15, No. 3  (Spring  1989) , pp. 30-37. 
Hasbrouck, J. and G. Saar.  “Low Latency Trading .” Working Paper, 2011.  
Iati, Robert.  “High Frequency Trading Technology .” TABB Group  (2009). 
http.//www.tabbgroup.com/PublicationDetail.aspx?PublicationID=498   
Jarrow, R. and P. Protter.  “A dysfunctional role of High Frequency Trading in electronic 
markets .” Johnson School R esearch Paper Series No. 8, 2011.  
Leinweber, D. Nerds on Wall Street : Math, Machines and Wired Markets . Wiley, 2009.  
Linton, O. and M. O’Hara.  “The Impact of Computer Trading on Liquidity, Price 
Efficiency/Discovery and Transactions Costs .” A part of the F oresight Project on The 
Future of Computer Trading in Financial Markets, U K Government Office for Science, 
2011.  
Mandelbrot, B., and M. Taylor . “On the Distribution of Stock Price Differences .” Operations 
Research, Vol. 15, No. 6 (1967), pp.  1057 -1062.  
Mandelbrot, B. . “Comments on ‘A subordinated stochastic process model with finite variance for 
speculative prices by Peter K. Clark’ .” Econometrica, Vol. 41, No. 1 (1967), pp.  157-159. 
NANEX.  “Strange Days June 8'th, 2011 - NatGas Algo .” 
www.nanex.net/StrangeDays/06082011.html  (2011).  
O’Hara, M.  “What is a quote?.”  Journal of Trading, (Spring  2011) , pp. 10-15. 
U.S. SEC, “Recommendations Regarding Regulatory Responses to the Marke t Events of May 6, 
2010: Summary Report of the Joint CFTC -SEC Advisory Committee on Emerging 
Regulatory Issues,” (February 18, 2011 ). Available at: http://www.sec.gov/spotlight/sec -
cftcjointcommittee/021811 -report.pdf   
The New York Times.  “Ex-Physicist Lea ds Flash Crash Inquiry .” 09/20 /2010 . 
Zhang, F.  “High frequency trading, stock volatility and price discovery .” Working P aper, 2010 . 
Available in SSRN.  
 
